{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEP Preprossessing\n",
    "\n",
    "In this notebook I manipulate watershed boundary layers used for the Massachusetts Estuaries Project, within [MEP study area](https://www.mass.gov/guides/the-massachusetts-estuaries-project-and-reports). \n",
    "\n",
    "1. Regroup subwatershed layers that were split by travel time.\n",
    "2. Calculate the elevation percentile in subs (Lid_Sub_ZS)\n",
    "3. Classify subwatersheds by elevation percentile (ele5pct_poly)\n",
    "4. Intersect elevation classes with subwatersheds (sub_le5pct)\n",
    "5. Intersect elevation classified subwatersheds with tax parcel data (subs_le5_tax)\n",
    "\n",
    "Tax parcel data can then be used to generate land cover classifications within subwatersheds uplands and terminal zones (seepage faces) of subwatersheds.\n",
    "\n",
    "NOTE: whenever you set up a new ArcGIS Pro project with python for batch processing make sure to uncheck `options > geoprocessing > 'add output datasets to open map'` this will save RAM and prevent crashes when you are looping through many files. \n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Consider doing more lidar based metrics such as topographix wetness index or topographic openess index\n",
    "\n",
    "Consider adding slope. \n",
    "\n",
    "Consider summarizing landuse for older years. \n",
    "\n",
    "## Data \n",
    "\n",
    "Publication\n",
    "Carlson, C.S., Masterson, J.P., Walter, D.A., and Barbaro, J.R., 2017, Development of simulated groundwater-contributing areas to selected streams, ponds, coastal water bodies, and production wells in the Plymouth-Carver region and Cape Cod, Massachusetts: U.S. Geological Survey Data Series 1074, 17 p. https://doi.org/10.3133/ds1074\n",
    "\n",
    "Dataset: \n",
    "Carlson, C.S., Masterson, J.P., Walter, D.A., and Barbaro, J.R., 2017, Simulated groundwater-contributing areas to selected streams, ponds, coastal water bodies, and production wells, Plymouth-Carver region and Cape Cod, Massachusetts: U.S. Geological Survey data release, https://doi.org/10.5066/F7V69H2Z.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "loading python modules...\n",
      "\n",
      "  `module_list` contains names of all loaded modules\n",
      "\n",
      "...module loading complete\n",
      "\n",
      "***\n",
      "loading user defined functions...\n",
      "\n",
      "type `fn_`+TAB to for autocomplete suggestions\n",
      "\n",
      " the object `def_list` contains user defined function names:\n",
      "   fn_get_info\n",
      "   fn_arcgis_table_to_df\n",
      "   fn_arcgis_table_to_np_to_pd_df\n",
      "   fn_try_mkdir\n",
      "   fn_hello\n",
      "   fn_recursive_glob_search\n",
      "   fn_regex_search_replace\n",
      "   fn_regex_search_0\n",
      "   fn_arcpy_table_to_excel\n",
      "   fn_agg_sum_df_on_group\n",
      "   fn_add_prefix_suffix_to_selected_cols\n",
      "   fn_calc_pct_cover_within_groups\n",
      "\n",
      " use ??{insert fn name} to inspect\n",
      " for example running `??fn_get_info` returns:\n",
      "\u001b[1;31mSignature:\u001b[0m \u001b[0mfn_get_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fn_get_info'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m   \n",
      "\u001b[1;32mdef\u001b[0m \u001b[0mfn_get_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fn_get_info'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m'''\n",
      "    returns the source information about a given function name\n",
      "    '''\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pinfo2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'$name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\workspace\\geodata\\mep\\<ipython-input-1-28f96385f735>\n",
      "\u001b[1;31mType:\u001b[0m      function\n",
      "\n",
      " you can also use `fn_get_info(name={insert fn name})` to do the same thing as `??{insert fn name}`\n",
      "\n",
      "...function loading complete\n",
      "\n",
      "\n",
      "***\n",
      "setting up arcpy environment...\n",
      "\n",
      " input file directory (`idr`): C:\\Workspace\\Geodata\\Massachusetts\\\n",
      " working directory (`wdr`): C:\\Workspace\\Geodata\\MEP\\\n",
      " default geodatabase path: C:\\Workspace\\Geodata\\MEP\\Default.gdb\n",
      " temp dir (`tdr`): <TemporaryDirectory 'C:\\\\Users\\\\ADRIAN~1.WIE\\\\AppData\\\\Local\\\\Temp\\\\ArcGISProTemp37644\\\\tmphekdrwco'>\n",
      " output dir (`odr`): C:\\Workspace\\Geodata\\MEP\\outputs\n",
      " output coordinate system: NAD_1983_UTM_Zone_19N\n",
      "\n",
      "... env setup complete\n",
      "\n",
      "\n",
      "+++SETUP COMPLETE+++\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this codeblock sets up the environment from jupyter notebooks\n",
    "setup_notebook = \"C:/Users/Adrian.Wiegman/Documents/GitHub/Wiegman_USDA_ARS/MEP/_Setup.ipynb\"\n",
    "%run $setup_notebook # magic command to run the notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MysticLakeE'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test function\n",
    "fn_regex_search_0('Mystic Lake GT10 E','\\w+10')\n",
    "fn_regex_search_replace('MysticLakeGT10E','\\wT10','')\n",
    "#fn_regex_search_replace('Mystic Lake  E','  ',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, June 26, 2023 9:16:15 PM\",\"Succeeded at Monday, June 26, 2023 9:16:16 PM (Elapsed Time: 0.44 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\outputs\\\\MEP_Subwatersheds_All_Copy.shp'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a working copy \n",
    "copyfile = r\"C:\\Workspace\\Geodata\\MEP\\outputs\\MEP_Subwatersheds_All_Copy.shp\"\n",
    "original = r\"C:\\Workspace\\Geodata\\MEP\\outputs\\MEP_Subwatersheds_All.shp\"\n",
    "#original = r\"C:\\Workspace\\Geodata\\Massachusetts\\MEP\\CC_MV_Subwatersheds\\Subwatersheds.shp\"\n",
    "arcpy.management.Copy(original, copyfile, \"ShapeFile\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, June 26, 2023 9:16:16 PM\",\"Sorting Attributes...\",\"Dissolving...\",\"Succeeded at Monday, June 26, 2023 9:16:17 PM (Elapsed Time: 1.09 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\MEP_Subwatersheds_Dissolve'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dissolve the MEP subwatersheds data\n",
    "outfile = os.path.join(\"MEP_Subwatersheds_Dissolve\")\n",
    "arcpy.management.Dissolve(copyfile, outfile, \"FID\", None, \"MULTI_PART\", \"DISSOLVE_LINES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a new feature class for subwatershed travel time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, June 26, 2023 9:16:17 PM\",\"Adding Travel_Tim to MEP_Subwatersheds_All_Copy...\",\"Succeeded at Monday, June 26, 2023 9:16:17 PM (Elapsed Time: 0.24 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\outputs\\\\MEP_Subwatersheds_All_Copy.shp'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a new feature class for subwatershed travel time. \n",
    "fn_string = \"\"\"def fn_regex_search_0 (string,pattern,noneVal=\"NA\"):\n",
    "    '''\n",
    "    returns the first match of a regular expression pattern search on a string\n",
    "    '''\n",
    "    import re\n",
    "    x = re.search(pattern,string)\n",
    "    if x is None: \n",
    "        x= [noneVal]    \n",
    "    return(x[0])\n",
    "    \"\"\"\n",
    "arcpy.management.CalculateField(copyfile,\n",
    "                                \"Travel_Tim\",\n",
    "                                \"fn_regex_search_0(!SUBWATER_D!,'\\wT10','NA')\",\n",
    "                                \"PYTHON3\",\n",
    "                                fn_string, \"TEXT\", \"NO_ENFORCE_DOMAINS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a new subwatershed name field that excludes travel time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, June 26, 2023 9:16:18 PM\",\"Succeeded at Monday, June 26, 2023 9:16:18 PM (Elapsed Time: 0.20 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\outputs\\\\MEP_Subwatersheds_All_Copy.shp'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a new subwatershed name field that excludes travel time\n",
    "fn_string = \"\"\"def fn_regex_search_replace(string,pattern,replacement):\n",
    "    '''\n",
    "    returns the a string with a pattern substituted by a replacement\n",
    "    '''\n",
    "    import re\n",
    "    x = re.sub(pattern,replacement,string)\n",
    "    return(x)\"\"\"\n",
    "newField = \"SUBW_NAME\"\n",
    "arcpy.management.CalculateField(copyfile,\n",
    "                                newField,\n",
    "                                \"\"\"fn_regex_search_replace(!SUBWATER_N!,\"\\wT10.*\",\"\")\"\"\", \n",
    "                                \"PYTHON3\",\n",
    "                                fn_string,\n",
    "                                \"TEXT\",\n",
    "                                \"NO_ENFORCE_DOMAINS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, June 26, 2023 9:16:18 PM\",\"Sorting Attributes...\",\"Dissolving...\",\"Succeeded at Monday, June 26, 2023 9:16:19 PM (Elapsed Time: 1.23 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\MEP_SUBW_NAME'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dissolve subwatersheds by subwatershed name.\n",
    "arcpy.management.Dissolve(copyfile,\n",
    "                          \"MEP_SUBW_NAME\", \n",
    "                          \"SUBW_NAME\", None, \"MULTI_PART\", \"DISSOLVE_LINES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the statewide lidar dataset with mask of subwatersheds\n",
    "raster = r\"C:\\Workspace\\Geodata\\Massachusetts\\LiDAR_DEM\\LiDAR_DEM.gdb\\LiDAR_DEM_INT_16bit\\Band_1\"\n",
    "mask = \"MEP_Subwatersheds_Dissolve\"\n",
    "\n",
    "lidar_extr = arcpy.sa.ExtractByMask(raster,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecuteError",
     "evalue": "ERROR 160333: The table was not found.\nFailed to execute (ExtractByMask).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "In  \u001b[0;34m[7]\u001b[0m:\nLine \u001b[0;34m5\u001b[0m:     lidar_extr = arcpy.sa.ExtractByMask(raster,mask)\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\sa\\Functions.py\u001b[0m, in \u001b[0;32mExtractByMask\u001b[0m:\nLine \u001b[0;34m4245\u001b[0m:  \u001b[34mreturn\u001b[39;49;00m Wrapper(\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\sa\\Utils.py\u001b[0m, in \u001b[0;32mswapper\u001b[0m:\nLine \u001b[0;34m55\u001b[0m:    result = wrapper(*args, **kwargs)\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\sa\\Functions.py\u001b[0m, in \u001b[0;32mWrapper\u001b[0m:\nLine \u001b[0;34m4238\u001b[0m:  result = arcpy.gp.ExtractByMask_sa(\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001b[0m, in \u001b[0;32m<lambda>\u001b[0m:\nLine \u001b[0;34m512\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m \u001b[34mlambda\u001b[39;49;00m *args: val(*gp_fixargs(args, \u001b[34mTrue\u001b[39;49;00m))\n",
      "\u001b[0;31mExecuteError\u001b[0m: ERROR 160333: The table was not found.\nFailed to execute (ExtractByMask).\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# this code worked\n",
    "out_raster = arcpy.sa.ExtractByMask(\n",
    "    in_raster=r\"C:\\Workspace\\Geodata\\Massachusetts\\LiDAR_DEM\\LiDAR_DEM.gdb\\LiDAR_DEM_INT_16bit\\Band_1\",\n",
    "    in_mask_data=\"MEP_Subwatersheds_Dissolve\",\n",
    "    extraction_area=\"INSIDE\",\n",
    "    analysis_extent='-7924126.67244911 5048924.87130968 -7783827.32899976 5173789.77853474 PROJCS[\"WGS_1984_Web_Mercator_Auxiliary_Sphere\",GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Mercator_Auxiliary_Sphere\"],PARAMETER[\"False_Easting\",0.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",0.0],PARAMETER[\"Standard_Parallel_1\",0.0],PARAMETER[\"Auxiliary_Sphere_Type\",0.0],UNIT[\"Meter\",1.0]]'\n",
    ")\n",
    "out_raster.save(r\"C:\\Workspace\\Geodata\\MEP\\Default.gdb\\Extract_LiDA1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outname = \"Extract_LiDA1\"\n",
    "lidar_extr.save(outname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zonal stats to calc 5th percentile of elevation in each subcatchment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "copyfile = r\"C:\\Workspace\\Geodata\\MEP\\outputs\\MEP_Subwatersheds_All_Copy.shp\"\n",
    "poly = copyfile\n",
    "zonefield = \"SUBW_NAME\"\n",
    "pct = 5  # 5% percentile\n",
    "outname = \"Lid_Sub_ZS\"\n",
    "Lid_Sub_ZS = arcpy.ia.ZonalStatistics(poly, \n",
    "                                      zonefield, \n",
    "                                      raster, \n",
    "                                      \"PERCENTILE\", \n",
    "                                      \"DATA\", \n",
    "                                      \"CURRENT_SLICE\", \n",
    "                                      pct, \n",
    "                                      \"AUTO_DETECT\"); \n",
    "Lid_Sub_ZS.save(os.path.join(outname))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# raster calculator to \n",
    "a = \"lidar_extr\"\n",
    "b = \"Lid_Sub_ZS\"\n",
    "outname = \"lidar_le5pct\"\n",
    "lidar_le5pct = arcpy.ia.RasterCalculator([a,b],\n",
    "                                          [\"a\", \"b\"],\n",
    "                                          \"a<=b\"); \n",
    "lidar_le5pct.save(os.path.join(odr,outname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract_LiDA1 Lid_Sub_ZS\n"
     ]
    }
   ],
   "source": [
    "a = \"Extract_LiDA1\"\n",
    "b = \"Lid_Sub_ZS\"\n",
    "print(a,b)\n",
    "lidar_le5pct = arcpy.ia.LessThanEqual(a,b); \n",
    "lidar_le5pct.save(\"lidar_bog_le5pct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert raster of lidar_le5pct to polygon\n",
    "outfile = \"lidar_bog_le5pct_poly\"\n",
    "poly = arcpy.conversion.RasterToPolygon(\"lidar_bog_le5pct\", outfile, \"SIMPLIFY\", \"VALUE\", \"SINGLE_OUTER_PART\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, June 27, 2023 10:32:29 AM\",\"Adding ele5pct to ele5pct_poly...\",\"Succeeded at Tuesday, June 27, 2023 10:32:47 AM (Elapsed Time: 17.92 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'ele5pct_poly'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfun = \"\"\"def fn(x):\n",
    "    y = \"GT5%\"\n",
    "    if x == 1: y = \"LE5%\"\n",
    "    return(y)\"\"\"\n",
    "# rename the field gridcode \n",
    "arcpy.management.CalculateField(outfile, \n",
    "                                \"ele5pct\", \n",
    "                                \"fn(!gridcode!)\", \n",
    "                                \"PYTHON3\", \n",
    "                                myfun, \"TEXT\", \"NO_ENFORCE_DOMAINS\")\n",
    "#arcpy.management.AlterField(outfile, 'gridcode', 'ElevLE5pct', 'Elev <= 5% percentile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, June 27, 2023 10:32:52 AM\",\"Sorting Attributes...\",\"Dissolving...\",\"Succeeded at Tuesday, June 27, 2023 10:33:17 AM (Elapsed Time: 24.23 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\ele5pct_poly_diss'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dissolve new polygon layer by elevation class \n",
    "arcpy.management.Dissolve(\"ele5pct_poly\",\n",
    "                          \"ele5pct_poly_diss\", \n",
    "                          \"ele5pct\", None, \"MULTI_PART\", \"DISSOLVE_LINES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, June 27, 2023 10:39:21 AM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Tuesday, June 27, 2023 10:39:40 AM (Elapsed Time: 19.29 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\subs_tt_le5pct'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the identity (intersection) of elevation poly and watershed poly\n",
    "infeat = \"ele5pct_poly_diss\"\n",
    "identfeat = copyfile\n",
    "outname = \"subs_tt_le5pct\"\n",
    "arcpy.analysis.Identity(infeat, identfeat, \n",
    "                        outname, \"ALL\", None, \"NO_RELATIONSHIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, June 27, 2023 10:40:39 AM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Tuesday, June 27, 2023 10:40:58 AM (Elapsed Time: 19.12 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\subs_le5pct'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the identity (intersection) of elevation poly and watershed poly\n",
    "# without travel times\n",
    "infeat = \"ele5pct_poly_diss\"\n",
    "identfeat = \"MEP_SUBW_NAME\"\n",
    "outname = \"subs_le5pct\"\n",
    "arcpy.analysis.Identity(infeat, identfeat, \n",
    "                        outname, \"ALL\", None, \"NO_RELATIONSHIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, June 27, 2023 10:41:04 AM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Tuesday, June 27, 2023 10:43:26 AM (Elapsed Time: 2 minutes 22 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\subs_le5_tax'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the identity (intersection) of elevation poly and watershed poly\n",
    "# without travel times\n",
    "infeat = \"subs_le5pct\"\n",
    "identfeat = \"MEP_TaxPar\"\n",
    "outname = \"subs_le5_tax\"\n",
    "arcpy.analysis.Identity(infeat, identfeat, \n",
    "                        outname, \"ALL\", None, \"NO_RELATIONSHIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, June 27, 2023 10:43:26 AM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Tuesday, June 27, 2023 10:45:52 AM (Elapsed Time: 2 minutes 25 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\subs_tt_le5_tax'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the identity (intersection) of elevation poly and watershed poly\n",
    "# with travel times\n",
    "infeat = \"subs_tt_le5pct\"\n",
    "identfeat = \"MEP_TaxPar\"\n",
    "outname = \"subs_tt_le5_tax\"\n",
    "arcpy.analysis.Identity(infeat, identfeat, \n",
    "                        outname, \"ALL\", None, \"NO_RELATIONSHIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, June 27, 2023 12:00:02 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Tuesday, June 27, 2023 12:00:43 PM (Elapsed Time: 40.78 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\subs_le5pct_soil20'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intersect sheds with soil\n",
    "arcpy.analysis.Identity(\"subs_le5pct\", \n",
    "                        r\"C:\\Workspace\\Geodata\\Massachusetts\\Soils_MassGIS.gdb\\SOILS_MUPOLYGON_TOP20\", \n",
    "                        r\"C:\\Workspace\\Geodata\\MEP\\Default.gdb\\subs_le5pct_soil20\", \"ALL\", None, \"NO_RELATIONSHIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, June 27, 2023 12:00:43 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Tuesday, June 27, 2023 12:01:23 PM (Elapsed Time: 39.99 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\subs_tt_le5_soil20'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intersect sheds with soil\n",
    "arcpy.analysis.Identity(\"subs_tt_le5pct\", \n",
    "                        r\"C:\\Workspace\\Geodata\\Massachusetts\\Soils_MassGIS.gdb\\SOILS_MUPOLYGON_TOP20\", \n",
    "                        r\"C:\\Workspace\\Geodata\\MEP\\Default.gdb\\subs_tt_le5_soil20\", \"ALL\", None, \"NO_RELATIONSHIPS\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# CAUTION: DO NOT RUN THIS CELL!!!!!!!!!!!!!!\n",
    "# intersect \n",
    "infeat = r\"C:\\Workspace\\Geodata\\Massachusetts\\lclu_gdb\\MA_LCLU2016.gdb\\LANDCOVER_LANDUSE_POLY\"\n",
    "clipfeat = \"MEP_SUBW_NAME\"\n",
    "outname = \"lclu16_clip\"\n",
    "arcpy.analysis.Clip(infeat, clipfeat, \"lclu16_clip\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, June 27, 2023 11:01:48 AM\",\"Reading Features...\",\"Processing Tiles...\",\"Assembling Tile Features...\",\"Succeeded at Tuesday, June 27, 2023 11:48:26 AM (Elapsed Time: 46 minutes 38 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\subs_le5_lclu16'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the itentity intersection of the output with the LCLU layer.\n",
    "infeat = \"subs_le5pct\"\n",
    "identfeat = r\"C:\\Workspace\\Geodata\\Massachusetts\\lclu_gdb\\MA_LCLU2016.gdb\\LANDCOVER_LANDUSE_POLY\"\n",
    "outname = 'subs_le5_lclu16'\n",
    "arcpy.analysis.Identity(infeat, identfeat, outname, \"ALL\", None, \"NO_RELATIONSHIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, June 27, 2023 12:01:23 PM\",\"Reading Features...\",\"Processing Tiles...\",\"Assembling Tile Features...\",\"Succeeded at Tuesday, June 27, 2023 12:40:31 PM (Elapsed Time: 39 minutes 7 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\subs_tt_le5_lclu16'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the itentity intersection of the output with the LCLU layer.\n",
    "infeat = \"subs_tt_le5pct\"\n",
    "identfeat = r\"C:\\Workspace\\Geodata\\Massachusetts\\lclu_gdb\\MA_LCLU2016.gdb\\LANDCOVER_LANDUSE_POLY\"\n",
    "outname = 'subs_tt_le5_lclu16'\n",
    "arcpy.analysis.Identity(infeat, identfeat, outname, \"ALL\", None, \"NO_RELATIONSHIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, June 27, 2023 11:54:16 AM\",\"Succeeded at Tuesday, June 27, 2023 11:54:17 AM (Elapsed Time: 0.60 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\outputs\\\\Cranberry_Copy.shp'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NEED TO UPDATE CRANBERRY LAYER WITH MORE RECENT LAND USE LAND COVER DATA\n",
    "# make a working copy of cranberry layer \n",
    "original = \"C:\\Workspace\\Geodata\\Massachusetts\\WMAbogsDRAFT2013\\WMAbogsDRAFT2013.shp\"\n",
    "\n",
    "# make a new column identifying all polygons as cranberry\n",
    "arcpy.management.CalculateField(\n",
    "    in_table=original,\n",
    "    field=\"CRANBERRY\",\n",
    "    expression=\"1\",\n",
    "    expression_type=\"PYTHON3\",\n",
    "    code_block=\"\",\n",
    "    field_type=\"TEXT\",\n",
    "    enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    ")\n",
    "\n",
    "# make a new column identifying actively farmed cranberry\n",
    "arcpy.management.CalculateField(\n",
    "    in_table=original,\n",
    "    field=\"ACTIVE\",\n",
    "    expression=\"fn(!CropStatus!)\",\n",
    "    expression_type=\"PYTHON3\",\n",
    "    code_block=\"\"\"def fn(x):\n",
    "    if x=='active':\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\"\"\",\n",
    "    field_type=\"TEXT\",\n",
    "    enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    ")\n",
    "\n",
    "copyfile = \"Cranberry_Copy\"\n",
    "arcpy.management.Copy(original, os.path.join(odr,copyfile), \"ShapeFile\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, June 27, 2023 11:54:28 AM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Tuesday, June 27, 2023 11:54:47 AM (Elapsed Time: 19.14 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\subs_le5_cran'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intersect cranberry layer with elevation subs. \n",
    "infeat = \"subs_le5pct\"\n",
    "identfeat = \"Cranberry_Copy\"\n",
    "outname = \"subs_le5_cran\"\n",
    "arcpy.analysis.Identity(infeat,identfeat,outname,join_attributes=\"ALL\",cluster_tolerance=None,relationship=\"NO_RELATIONSHIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, June 27, 2023 3:56:59 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Tuesday, June 27, 2023 3:57:15 PM (Elapsed Time: 15.89 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\subs_tt_le5_cran'>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intersect cranberry layer with elevation subs. \n",
    "# compute the itentity intersection of the output with the LCLU layer.\n",
    "infeat = \"subs_tt_le5pct\"\n",
    "identfeat = \"Cranberry_Copy\"\n",
    "outname = \"subs_tt_le5_cran\"\n",
    "arcpy.analysis.Identity(infeat,identfeat,outname,join_attributes=\"ALL\",cluster_tolerance=None,relationship=\"NO_RELATIONSHIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-03-30 RESUME HERE! \n",
    "# export feature table data \n",
    "print(def_list)\n",
    "\n",
    "# the functions below provide options to export feature tables \n",
    "??fn_arcpy_table_to_excel\n",
    "#fn_arcpy_table_to_excel(inFeaturePath,outTablePath=odr,outTableName=\"SUBS_TaxParAssess.xlsx\")\n",
    "\n",
    "??fn_arcgis_table_to_df #this one works better\n",
    "\n",
    "??fn_arcgis_table_to_np_to_pd_df # this one doesn't work very well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'Shape', 'FID_ele5pct_poly_diss', 'ele5pct', 'FID_MEP_Subwatersheds_All_Copy', 'sf_area', 'SubWat_Num', 'New_ID', 'ft_perim', 'SubW_Names', 'SHED_ID', 'Terminal_N', 'F_', 'Area_Ha', 'MAD_HBR_ID', 'Sub_Name', 'AREA', 'PERIMETER', 'NAME', 'Subwatersh', 'sqft_perim', 'sqft_area', 'WS_Num', 'p', 'a', 'OBJECTID_1', 'ISLAND', 'Shape_Leng', 'Subw_New', 'mt_perim', 'sm_area', 'Id', 'MapID', 'EelRiv_WS', 'PlyHar_WS', 'SUB_WS', 'REV_SUBW', 'SUBW_NAME', 'Subw', 'SubID', 'ACRES', 'FID_nb_wat', 'WATERSHED2', 'WATERSHED3', 'FID_acushn', 'fst_SHED_I', 'OBJECTID_12', 'SUBWATER_I', 'SUBWATER_N', 'SUBWATER_D', 'EMBAY_ID', 'EMBAY_NAME', 'EMBAY_DISP', 'X_Centroid', 'Y_Centroid', 'Acreage', 'GeoString', 'S_N', 'Travel_Tim', 'Shape_Length', 'Shape_Area']\n"
     ]
    }
   ],
   "source": [
    "infeat = 'subs_tt_le5pct'\n",
    "field_names = [f.name for f in arcpy.ListFields(infeat)]\n",
    "print(field_names)\n",
    "\n",
    "# convert feature table to pandas data frame\n",
    "df = fn_arcgis_table_to_df(in_fc=infeat)\n",
    "\n",
    "# remove unwanted columns\n",
    "selected_fields = ['OBJECTID','SUBW_NAME','LOC_ID','ele5pct','Travel_Tim',\"EMBAY_NAME\",\"SUBWATER_N\",'CropStatus', 'FID_Cranberry_Copy','WMA_NO','BOG_NAME','COMMENT','OWNER_FIRS', 'OWNER_LAST','COMMENT','CRANBERRY', 'ACTIVE', 'Shape_Length', 'Shape_Area']\n",
    "df_select =df.filter(selected_fields,axis=1) # filter columns on index; use axis = 1 for cols use axis = 0 for rows)\n",
    "\n",
    "# save pickle\n",
    "#df.to_pickle(os.path.join(odr,'df_'+infeat+'.pkl'))\n",
    "df_select.to_pickle(os.path.join(odr,'df_'+infeat+'_select.pkl'))\n",
    "\n",
    "# save csv\n",
    "#df.to_csv(os.path.join(odr,'df_'+infeat+'.csv'))\n",
    "df_select.to_csv(os.path.join(odr,'df_'+infeat+'_select.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'Shape', 'FID_subs_tt_le5pct', 'FID_ele5pct_poly_diss', 'ele5pct', 'FID_MEP_Subwatersheds_All_Copy', 'sf_area', 'SubWat_Num', 'New_ID', 'ft_perim', 'SubW_Names', 'SHED_ID', 'Terminal_N', 'F_', 'Area_Ha', 'MAD_HBR_ID', 'Sub_Name', 'AREA', 'PERIMETER', 'NAME', 'Subwatersh', 'sqft_perim', 'sqft_area', 'WS_Num', 'p', 'a', 'OBJECTID_1', 'ISLAND', 'Shape_Leng', 'Subw_New', 'mt_perim', 'sm_area', 'Id', 'MapID', 'EelRiv_WS', 'PlyHar_WS', 'SUB_WS', 'REV_SUBW', 'SUBW_NAME', 'Subw', 'SubID', 'ACRES', 'FID_nb_wat', 'WATERSHED2', 'WATERSHED3', 'FID_acushn', 'fst_SHED_I', 'OBJECTID_12', 'SUBWATER_I', 'SUBWATER_N', 'SUBWATER_D', 'EMBAY_ID', 'EMBAY_NAME', 'EMBAY_DISP', 'X_Centroid', 'Y_Centroid', 'Acreage', 'GeoString', 'S_N', 'Travel_Tim', 'FID_Cranberry_Copy', 'ID_1', 'WMA_NO', 'OWNER', 'ADDRESS', 'TOWN', 'REGION', 'BOG_NAME', 'REGAREA', 'CERTAREA', 'CREDITAREA', 'PERMITAREA', 'TOTAREA', 'STAFF', 'PROGRAM', 'DATE_ENTER', 'COMMENT', 'BIRTHREG', 'AREA_1', 'PERIMETER_1', 'PERMIT_NUM', 'OWNER_FIRS', 'OWNER_LAST', 'AREASACRES', 'Basin', 'CropStatus', 'CRANBERRY', 'ACTIVE', 'Shape_Length', 'Shape_Area']\n"
     ]
    }
   ],
   "source": [
    "infeat = \"subs_tt_le5_cran\"\n",
    "field_names = [f.name for f in arcpy.ListFields(infeat)]\n",
    "print(field_names)\n",
    "\n",
    "# convert feature table to pandas data frame\n",
    "df = fn_arcgis_table_to_df(in_fc=infeat)\n",
    "\n",
    "# remove unwanted columns\n",
    "selected_fields = ['OBJECTID','SUBW_NAME','LOC_ID','ele5pct','Travel_Tim',\"EMBAY_NAME\",\"SUBWATER_N\",'CropStatus','WMA_NO','BOG_NAME','COMMENT','Owner','OWNER_FIRS', 'OWNER_LAST','COMMENT','CRANBERRY', 'ACTIVE', 'Shape_Length', 'Shape_Area']\n",
    "df_select =df.filter(selected_fields,axis=1) # filter columns on index; use axis = 1 for cols use axis = 0 for rows)\n",
    "\n",
    "# save pickle\n",
    "#df.to_pickle(os.path.join(odr,'df_'+infeat+'.pkl'))\n",
    "df_select.to_pickle(os.path.join(odr,'df_'+infeat+'_select.pkl'))\n",
    "\n",
    "# save csv\n",
    "#df.to_csv(os.path.join(odr,'df_'+infeat+'.csv'))\n",
    "df_select.to_csv(os.path.join(odr,'df_'+infeat+'_select.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'Shape', 'FID_subs_tt_le5pct', 'FID_ele5pct_poly_diss', 'ele5pct', 'FID_MEP_Subwatersheds_All_Copy', 'sf_area', 'SubWat_Num', 'New_ID', 'ft_perim', 'SubW_Names', 'SHED_ID', 'Terminal_N', 'F_', 'Area_Ha', 'MAD_HBR_ID', 'Sub_Name', 'AREA', 'PERIMETER', 'NAME', 'Subwatersh', 'sqft_perim', 'sqft_area', 'WS_Num', 'p', 'a', 'OBJECTID_1', 'ISLAND', 'Shape_Leng', 'Subw_New', 'mt_perim', 'sm_area', 'Id', 'MapID', 'EelRiv_WS', 'PlyHar_WS', 'SUB_WS', 'REV_SUBW', 'SUBW_NAME', 'Subw', 'SubID', 'ACRES', 'FID_nb_wat', 'WATERSHED2', 'WATERSHED3', 'FID_acushn', 'fst_SHED_I', 'OBJECTID_12', 'SUBWATER_I', 'SUBWATER_N', 'SUBWATER_D', 'EMBAY_ID', 'EMBAY_NAME', 'EMBAY_DISP', 'X_Centroid', 'Y_Centroid', 'Acreage', 'GeoString', 'S_N', 'Travel_Tim', 'FID_MEP_TaxPar', 'MAP_PAR_ID', 'LOC_ID', 'POLY_TYPE', 'MAP_NO', 'SOURCE', 'PLAN_ID', 'LAST_EDIT', 'BND_CHK', 'NO_MATCH', 'TOWN_ID', 'MERGE_SRC', 'Shape_Length', 'Shape_Area']\n"
     ]
    }
   ],
   "source": [
    "infeat = 'subs_tt_le5_tax'\n",
    "field_names = [f.name for f in arcpy.ListFields(infeat)]\n",
    "print(field_names)\n",
    "\n",
    "# convert feature table to pandas data frame\n",
    "df = fn_arcgis_table_to_df(in_fc=infeat)\n",
    "\n",
    "# remove unwanted columns\n",
    "selected_fields = ['OBJECTID','SUBW_NAME','LOC_ID','ele5pct','Travel_Tim',\"EMBAY_NAME\",\"SUBWATER_N\",\"Shape_Length\",\"Shape_Area\"]\n",
    "df_select =df.filter(selected_fields,axis=1) # filter columns on index; use axis = 1 for cols use axis = 0 for rows)\n",
    "\n",
    "# save pickle\n",
    "#df.to_pickle(os.path.join(odr,'df_'+infeat+'.pkl'))\n",
    "df_select.to_pickle(os.path.join(odr,'df_'+infeat+'_select.pkl'))\n",
    "\n",
    "# save csv\n",
    "#df.to_csv(os.path.join(odr,'df_'+infeat+'.csv'))\n",
    "df_select.to_csv(os.path.join(odr,'df_'+infeat+'_select.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'Shape', 'FID_subs_tt_le5pct', 'FID_ele5pct_poly_diss', 'ele5pct', 'FID_MEP_Subwatersheds_All_Copy', 'sf_area', 'SubWat_Num', 'New_ID', 'ft_perim', 'SubW_Names', 'SHED_ID', 'Terminal_N', 'F_', 'Area_Ha', 'MAD_HBR_ID', 'Sub_Name', 'AREA', 'PERIMETER', 'NAME', 'Subwatersh', 'sqft_perim', 'sqft_area', 'WS_Num', 'p', 'a', 'OBJECTID_1', 'ISLAND', 'Shape_Leng', 'Subw_New', 'mt_perim', 'sm_area', 'Id', 'MapID', 'EelRiv_WS', 'PlyHar_WS', 'SUB_WS', 'REV_SUBW', 'SUBW_NAME', 'Subw', 'SubID', 'ACRES', 'FID_nb_wat', 'WATERSHED2', 'WATERSHED3', 'FID_acushn', 'fst_SHED_I', 'OBJECTID_12', 'SUBWATER_I', 'SUBWATER_N', 'SUBWATER_D', 'EMBAY_ID', 'EMBAY_NAME', 'EMBAY_DISP', 'X_Centroid', 'Y_Centroid', 'Acreage', 'GeoString', 'S_N', 'Travel_Tim', 'FID_SOILS_MUPOLYGON_TOP20', 'AREASYMBOL', 'SPATIALVER', 'MUSYM', 'MUKEY', 'SS_AREA', 'MUSYM_AREA', 'SLOPE', 'AREANAME', 'MUNAME', 'COMPNAME', 'MUKIND', 'FRMLNDCLS', 'HYDRCRATNG', 'DRAINCLASS', 'MINSURFTEXT', 'TFACTOR', 'AWS100', 'AWS25', 'DEP2WATTBL', 'DWELLWB', 'HYDROLGRP', 'NIRRLCC', 'ROADS', 'SEPTANKAF', 'SLOPE_1', 'FLOODING', 'PONDING', 'CORCONCRET', 'TAXCLNAME', 'CM2RESLYR', 'RESKIND', 'PARMATNM', 'UNIFSOILCL', 'AASHTO', 'KFACTRF', 'KFACTWS', 'PHWATER', 'CLAY', 'KSAT', 'OM', 'SAND', 'NLEACHING', 'Shape_Length', 'Shape_Area']\n"
     ]
    }
   ],
   "source": [
    "infeat = 'subs_tt_le5_soil20'\n",
    "field_names = [f.name for f in arcpy.ListFields(infeat)]\n",
    "print(field_names)\n",
    "\n",
    "# convert feature table to pandas data frame\n",
    "df = fn_arcgis_table_to_df(in_fc=infeat)\n",
    "\n",
    "# remove unwanted columns\n",
    "selected_fields = ['OBJECTID','SUBW_NAME','LOC_ID','ele5pct','Travel_Tim',\"EMBAY_NAME\",\"SUBWATER_N\",\"Shape_Length\",\"Shape_Area\", # watershed attributes\n",
    "                  \"COMPNAME\",\"SLOPE\",\"SLOPE_1\",\"FRMLNDCLS\",'HYDROLGRP','HYDRCRATNG','DRAINCLASS','DEP2WATTBL',\n",
    "                   'ROADS', 'SEPTANKAF', 'SLOPE_1', 'FLOODING', 'PONDING', 'CORCONCRET',\n",
    "                  'PHWATER', 'CLAY', 'KSAT', 'OM', 'SAND', 'NLEACHING'] #soil attributes\n",
    "df_select =df.filter(selected_fields,axis=1) # filter columns on index; use axis = 1 for cols use axis = 0 for rows)\n",
    "\n",
    "# save pickle\n",
    "#df.to_pickle(os.path.join(odr,'df_'+infeat+'.pkl'))\n",
    "df_select.to_pickle(os.path.join(odr,'df_'+infeat+'_select.pkl'))\n",
    "\n",
    "# save csv\n",
    "#df.to_csv(os.path.join(odr,'df_'+infeat+'.csv'))\n",
    "df_select.to_csv(os.path.join(odr,'df_'+infeat+'_select.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'Shape', 'FID_subs_tt_le5pct', 'FID_ele5pct_poly_diss', 'ele5pct', 'FID_MEP_Subwatersheds_All_Copy', 'sf_area', 'SubWat_Num', 'New_ID', 'ft_perim', 'SubW_Names', 'SHED_ID', 'Terminal_N', 'F_', 'Area_Ha', 'MAD_HBR_ID', 'Sub_Name', 'AREA', 'PERIMETER', 'NAME', 'Subwatersh', 'sqft_perim', 'sqft_area', 'WS_Num', 'p', 'a', 'OBJECTID_1', 'ISLAND', 'Shape_Leng', 'Subw_New', 'mt_perim', 'sm_area', 'Id', 'MapID', 'EelRiv_WS', 'PlyHar_WS', 'SUB_WS', 'REV_SUBW', 'SUBW_NAME', 'Subw', 'SubID', 'ACRES', 'FID_nb_wat', 'WATERSHED2', 'WATERSHED3', 'FID_acushn', 'fst_SHED_I', 'OBJECTID_12', 'SUBWATER_I', 'SUBWATER_N', 'SUBWATER_D', 'EMBAY_ID', 'EMBAY_NAME', 'EMBAY_DISP', 'X_Centroid', 'Y_Centroid', 'Acreage', 'GeoString', 'S_N', 'Travel_Tim', 'FID_LANDCOVER_LANDUSE_POLY', 'COVERNAME', 'COVERCODE', 'USEGENNAME', 'USEGENCODE', 'USE_CODE', 'POLY_TYPE', 'FY', 'TOWN_ID', 'TILENAME', 'Shape_Length', 'Shape_Area']\n"
     ]
    }
   ],
   "source": [
    "infeat = 'subs_tt_le5_lclu16'\n",
    "field_names = [f.name for f in arcpy.ListFields(infeat)]\n",
    "print(field_names)\n",
    "\n",
    "# convert feature table to pandas data frame\n",
    "df = fn_arcgis_table_to_df(in_fc=infeat)\n",
    "\n",
    "# remove unwanted columns\n",
    "selected_fields = ['OBJECTID','SUBW_NAME','LOC_ID','ele5pct','Travel_Tim',\"EMBAY_NAME\",\"SUBWATER_N\",\"Shape_Length\",\"Shape_Area\", # watershed attributes\n",
    "                  \"USE_CODE\",\"USEGENCODE\",\"COVERCODE\",\"COVERNAME\",'USEGENNAME'] #land use attributes\n",
    "df_select =df.filter(selected_fields,axis=1) # filter columns on index; use axis = 1 for cols use axis = 0 for rows)\n",
    "\n",
    "# save pickle\n",
    "#df.to_pickle(os.path.join(odr,'df_'+infeat+'.pkl'))\n",
    "df_select.to_pickle(os.path.join(odr,'df_'+infeat+'_select.pkl'))\n",
    "\n",
    "# save csv\n",
    "#df.to_csv(os.path.join(odr,'df_'+infeat+'.csv'))\n",
    "df_select.to_csv(os.path.join(odr,'df_'+infeat+'_select.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'Shape', 'FID_ele5pct_poly_diss', 'ele5pct', 'FID_MEP_SUBW_NAME', 'SUBW_NAME', 'Shape_Length', 'Shape_Area']\n"
     ]
    }
   ],
   "source": [
    "infeat = 'subs_le5pct'\n",
    "field_names = [f.name for f in arcpy.ListFields(infeat)]\n",
    "print(field_names)\n",
    "\n",
    "# convert feature table to pandas data frame\n",
    "df = fn_arcgis_table_to_df(in_fc=infeat)\n",
    "\n",
    "# remove unwanted columns\n",
    "selected_fields = ['OBJECTID','SUBW_NAME','ele5pct','Travel_Tim',\"EMBAY_NAME\",\"SUBWATER_N\",\"Shape_Length\",\"Shape_Area\"]\n",
    "df_select =df.filter(selected_fields,axis=1) # filter columns on index; use axis = 1 for cols use axis = 0 for rows)\n",
    "\n",
    "# save pickle\n",
    "df.to_pickle(os.path.join(odr,'df_'+infeat+'.pkl'))\n",
    "df_select.to_pickle(os.path.join(odr,'df_'+infeat+'_select.pkl'))\n",
    "\n",
    "# save csv\n",
    "df.to_csv(os.path.join(odr,'df_'+infeat+'.csv'))\n",
    "df_select.to_csv(os.path.join(odr,'df_'+infeat+'_select.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBW_NAME</th>\n",
       "      <th>ele5pct</th>\n",
       "      <th>Shape_Length</th>\n",
       "      <th>Shape_Area</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBJECTID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>GT5%</td>\n",
       "      <td>259724.234855</td>\n",
       "      <td>1.266637e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>LE5%</td>\n",
       "      <td>49691.267685</td>\n",
       "      <td>3.250521e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>GT5%</td>\n",
       "      <td>508668.060522</td>\n",
       "      <td>1.272824e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4Ponds</td>\n",
       "      <td>GT5%</td>\n",
       "      <td>14768.315875</td>\n",
       "      <td>1.404234e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AbnerPond</td>\n",
       "      <td>GT5%</td>\n",
       "      <td>3851.691608</td>\n",
       "      <td>3.355843e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SUBW_NAME ele5pct   Shape_Length    Shape_Area\n",
       "OBJECTID                                                \n",
       "1                      GT5%  259724.234855  1.266637e+04\n",
       "2                      LE5%   49691.267685  3.250521e+03\n",
       "3                      GT5%  508668.060522  1.272824e+08\n",
       "4            4Ponds    GT5%   14768.315875  1.404234e+06\n",
       "5         AbnerPond    GT5%    3851.691608  3.355843e+05"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join table with tax parcel assessor data\n",
    "df_select.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a new feature class subwatershed ids exluding travel time\n",
    "\n",
    "make new sub watershed layer that combines subwatersheds that were split by travel time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Make a point feature layer from monitoring coordinates\n",
    "# Set the local variables\n",
    "in_table = r\"C:\\Users\\Adrian.Wiegman\\OneDrive - USDA\\Research\\Nload\\MEP\\MEP_Summary4_AW.xlsx\\Coords$\"\n",
    "#in_table = r\"C:\\Users\\Adrian.Wiegman\\OneDrive - USDA\\Research\\Nload\\MEP\\MEP_Monitoring_Site_Coords.csv\"\n",
    "out_feature_class = \"MEP_Monitoring_Site_Coords\"\n",
    "x_coords = \"Lon\"\n",
    "y_coords = \"Lat\"\n",
    "\n",
    "# Make the XY event layer...\n",
    "arcpy.management.XYTableToPoint(in_table=in_table, \n",
    "                                out_feature_class=out_feature_class,\n",
    "                                x_field=x_coords, \n",
    "                                y_field=y_coords)\n",
    "\n",
    "# Print the total rows\n",
    "print(arcpy.management.GetCount(out_feature_class))\n",
    "#arcpy.management.AddJoin(out_feature_class, \"OBJECTID\", r\"C:\\Users\\Adrian.Wiegman\\OneDrive - USDA\\Research\\Nload\\MEP\\MEP_Monitoring_Site_Coords.csv\", \"OID\", \"KEEP_ALL\", \"NO_INDEX_JOIN_FIELDS\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inlayer = \"MEP_Monitoring_Sites_MeasOnly\"\n",
    "#copyfile = \"MEP_Monitoring_Sites_Copy\"\n",
    "#arcpy.management.Copy(original, copyfile, None)\n",
    "#arcpy.env.overwriteOutput = 1\n",
    "arcpy.management.AddJoin(\n",
    "    in_layer_or_view=inlayer,\n",
    "    in_field=\"OBJECTID\",\n",
    "    join_table=r\"C:\\Users\\Adrian.Wiegman\\Documents\\GitHub\\Wiegman_USDA_ARS\\MEP\\data\\MEP_SummaryData_Coords.csv\",\n",
    "    join_field=\"idn\",\n",
    "    join_type=\"KEEP_ALL\",\n",
    "    index_join_fields=\"INDEX_JOIN_FIELDS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unused code snippets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# clip the MassGIS 2016 landcover 0.5m layer with the mep watershed layer. \n",
    "# arcgis does not like this for whatever reason. \n",
    "cliplayer = os.path.join(odr,\"MEP_Subwatersheds_Dissolve\")\n",
    "outfile='lclu16_mep_clip'\n",
    "inlayer= 'Land Cover Land Use (2016)'\n",
    "lclu16_clip = arcpy.analysis.Clip(inlayer,cliplayer,outfile, None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "USGS_startDir = r'C:\\Workspace\\Geodata\\Massachusetts\\USGS_\\SimulatedGround\\original_USGS_areas\\original_USGS_areas'\n",
    "All_USGS_paths = fn_recursive_glob_search(USGS_startDir,'.shp')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# clip land use for aquifer extent\n",
    "arcpy.analysis.Clip(r\"C:\\Workspace\\Geodata\\Massachusetts\\lclu_gdb\\MA_LCLU2016.gdb\\LANDCOVER_LANDUSE_POLY\", \"MEP_Subwatersheds\", r\"C:\\Workspace\\Geodata\\Nload\\outputs\\MEP\\LCLU2016_MEP_Clip\", None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
