{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for ArcGIS workflows\n",
    "\n",
    "Author: Adrian Wiegman, adrian.wiegman@usda.gov\n",
    "\n",
    "Created: 10:05 AM Thursday, March 30, 2023\n",
    "\n",
    "Updated: April 18, 2023\n",
    "\n",
    "Notes and Instructions:\n",
    "\n",
    "This script contains helper functions for arcgis workflow to analyze land use and other datasets within watersheds. \n",
    "\n",
    "- prefix all user defined functions with `fn_`\n",
    "- place working functions in the main program\n",
    "- place broken functions in the appendix and comment out or convert cell to Raw NBConvert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program\n",
    "\n",
    "functions in this section have been checked and debugged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type `fn_`+TAB to for autocomplete suggestions\n"
     ]
    }
   ],
   "source": [
    "print('type `fn_`+TAB to for autocomplete suggestions')\n",
    "\n",
    "def fn_get_info(name='fn_get_info'):\n",
    "    '''\n",
    "    returns the source information about a given function name\n",
    "    '''\n",
    "    ??$name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this codeblock appends a path to source codes to the environment variable paths\n",
    "# then runs a script containing other source codes\n",
    "import sys\n",
    "# Insert the path of modules folder \n",
    "sys.path.append(r\"C:\\Users\\Adrian.Wiegman\\Documents\\GitHub\\Wiegman_USDA_ARS\\MEP\\scripts\")\n",
    "# Import the module0 directly since \n",
    "# the current path is of modules.\n",
    "%run -m _FeatureTableToDataFrame \n",
    "# the line above runs the script named _FeaturedTableToDataFrame.py from within the path .../scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_run_script_w_propy_bat(\n",
    "    py_script_path=None, # full path to python script includeing the name e.g. \"C:\\hello.py\"\n",
    "    propy_bat_path=\"C:\\Progra~1\\ArcGIS\\Pro\\\\bin\\Python\\Scripts\"\n",
    "    ):\n",
    "    '''\n",
    "    this function can be used to execute standalone python scripts in the ArcGIS python environment using the command line\n",
    "    the benefit of this is that arcpy can be used without opening arcgis\n",
    "    read more: https://pro.arcgis.com/en/pro-app/latest/arcpy/get-started/using-conda-with-arcgis-pro.htm\n",
    "    '''\n",
    "    import os\n",
    "    # create temporary file for testing the function\n",
    "    if py_script_path is None:\n",
    "        import tempfile\n",
    "        tmpdir = tempfile.TemporaryDirectory()\n",
    "        py_script_path = os.path.join(tmpdir.name,\"hello.py\")\n",
    "            # Open the file for writing.\n",
    "        with open(py_script_path, 'w') as f:\n",
    "            f.write(\"print('Hello World!')\")\n",
    "\n",
    "    # get current working directory\n",
    "    wdr = os.getcwd()\n",
    "    \n",
    "    # change directory to folder containing propy.bat\n",
    "    os.chdir(propy_bat_path) \n",
    "    \n",
    "    # construct cmd\n",
    "    cmd = \"propy.bat {}\".format(py_script_path)\n",
    "    \n",
    "    print(\"running command:\\n\")\n",
    "    print(\"{}\\{}\".format(propy_bat_path,cmd))\n",
    "    # execute cmd\n",
    "    os.system(cmd)\n",
    "    \n",
    "    # change directory back \n",
    "    os.chdir(wdr)\n",
    "#fn_run_script_w_propy_bat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_try_mkdir(dirname):\n",
    "    '''\n",
    "    tries to make a new directory\n",
    "    uses proper error handling \n",
    "    '''\n",
    "    import os, errno\n",
    "    try:\n",
    "        os.mkdir(dirname)\n",
    "    except OSError as exc:\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_hello(x=\"world\"):\n",
    "    '''\n",
    "    prints hello x\n",
    "    '''\n",
    "    print(\"hello %s\" %x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_recursive_glob_search (startDir=None,\n",
    "                             fileExt=\"csv\"):\n",
    "    '''returns:\n",
    "           file paths matching extension \n",
    "           within all subdirectories starting directory\n",
    "       inputs:\n",
    "           startDir = root or parent directory to start search\n",
    "           fileExt = file extension, e.g. \".csv\" \".xlsx\" \".shp\"\n",
    "    '''\n",
    "    import glob, os\n",
    "    if startDir is None:\n",
    "        startDir = os.getcwd\n",
    "    fileList = []\n",
    "    glbsearch = os.path.join(startDir,'**/*'+fileExt)\n",
    "    for f in glob.glob(glbsearch, recursive=True):\n",
    "        #print(f)\n",
    "        fileList.append(f)\n",
    "    return(fileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_regex_search_replace(string,pattern,replacement=None):\n",
    "    '''\n",
    "    returns the a string with a pattern substituted by a replacement\n",
    "    '''\n",
    "    if replacement is None: replacement = \"\"\n",
    "    import re\n",
    "    x = re.sub(pattern,replacement,string)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_regex_search_0 (string,pattern,noneVal=\"NA\"):\n",
    "    '''\n",
    "    returns the first match of a regular expression pattern search on a string\n",
    "    '''\n",
    "    import re\n",
    "    x = re.search(pattern,string)\n",
    "    if x is None: \n",
    "        x= [noneVal]    \n",
    "    return(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_arcpy_table_to_excel(inFeaturePath,outTablePath,outTableName):\n",
    "    import os\n",
    "    arcpy.conversion.TableToExcel(inFeaturePath, os.path.join(outTablePath,outTableName), \"ALIAS\", \"CODE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_agg_sum_df_on_group(group_cols,df,func=sum):\n",
    "    '''\n",
    "    returns data frame aggregated on set of group_cols for given a func\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    return df.groupby(group_cols).aggregate(func).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_add_prefix_suffix_to_selected_cols(df,col_names,prefix=None,suffix=None,sep='_'):\n",
    "    # use list comprehension to add prefix and/or suffix to old names\n",
    "    _ = [i if prefix is None else prefix+sep+i for i in col_names]\n",
    "    new_names = [i if suffix is None else i+sep+suffix for i in _]\n",
    "    df.rename(columns=dict(zip(col_names, new_names)), inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_calc_pct_cover_within_groups(group_cols,x,area_col='Shape_Area'):\n",
    "    '''\n",
    "    calculates percent cover normalize metrics by polygon area\n",
    "    inputs:\n",
    "        x = pandas dataframe containing the following columns\n",
    "        group_cols = a list of strings containing group column names\n",
    "        area_col = string containing the name of the shape area column\n",
    "    all other columns must be numeric columns containing areas of various attribute types \n",
    "    all other columns must have the same units as area_col\n",
    "    '''\n",
    "    x\n",
    "    # copy the numeric columns that are not groups or the selected area column \n",
    "    _ = x.loc[:, ~x.columns.isin(group_cols+[area_col])]._get_numeric_data()\n",
    "    \n",
    "    # divide the \n",
    "    y = _.div(x[area_col],axis=0).mul(100)\n",
    "    if 'Shape_Length' in y.columns:\n",
    "        y.rename(columns={'Shape_Length':'Shape_Perim_to_Area'},inplace=True)\n",
    "    # merge the data back together\n",
    "    z = pd.merge(x[group_cols],x[area_col],left_index=True,right_index=True).merge(y,left_index=True, right_index=True)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_buildWhereClauseFromList(table, # name of table\n",
    "                                field, # name of field to search\n",
    "                                valueList # list of values for the SQL query\n",
    "                               ):\n",
    "    \n",
    "    \"\"\"Takes a list of values and constructs a SQL WHERE\n",
    "    clause to select those values within a given field and table.\"\"\"\n",
    "\n",
    "    # Add DBMS-specific field delimiters\n",
    "    fieldDelimited = arcpy.AddFieldDelimiters(arcpy.Describe(table).path, field)\n",
    "\n",
    "    # Determine field type\n",
    "    fieldType = arcpy.ListFields(table, field)[0].type\n",
    "\n",
    "    # Add single-quotes for string field values\n",
    "    if str(fieldType) == 'String':\n",
    "        valueList = [\"'%s'\" % value for value in valueList]\n",
    "\n",
    "    # Format WHERE clause in the form of an IN statement\n",
    "    whereClause = \"%s IN(%s)\" % (fieldDelimited, ', '.join(map(str, valueList)))\n",
    "    return whereClause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get extract the cell size of raster\n",
    "def fn_FA_to_Q (rasterpath=None,recharge_rate_in_yr = 27.25):\n",
    "    _ = arcpy.GetRasterProperties_management(rasterpath, \"CELLSIZEX\")\n",
    "    #Get the elevation standard deviation value from geoprocessing result object\n",
    "    cellsize_x = _.getOutput(0)\n",
    "    _ = arcpy.GetRasterProperties_management(rasterpath, \"CELLSIZEY\")\n",
    "    cellsize_y = _.getOutput(0)\n",
    "    # calculate cell area in meters\n",
    "    cell_area_meters = float(cellsize_x) * float(cellsize_y)\n",
    "    print(cell_area_meters)\n",
    "    FA_to_Q = cell_area_meters * recharge_rate_in_yr * 2.54 * (1/100) * (1/365.25)\n",
    "    print(FA_to_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_alter_field_double(intablepath,oldname,newname):\n",
    "    '''\n",
    "    renames a field in a table if the field is a double\n",
    "    '''\n",
    "    arcpy.management.AlterField(\n",
    "        in_table=intablepath,\n",
    "        field=oldname,\n",
    "        new_field_name=newname,\n",
    "        new_field_alias=\"\",\n",
    "        field_type=\"DOUBLE\",\n",
    "        field_length=16,\n",
    "        field_is_nullable=\"NULLABLE\",\n",
    "        clear_field_alias=\"CLEAR_ALIAS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_return_float(x):\n",
    "    \"\"\"\n",
    "    returns an object of type float\n",
    "    \"\"\"\n",
    "    try: \n",
    "        return(float(x))\n",
    "    except:\n",
    "        return(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_classify_wetlands(x):\n",
    "    \"\"\"\n",
    "    Consolidates DEP wetlands into fewer categories\n",
    "    \"\"\"\n",
    "    if \"MARSH\" in x:\n",
    "        return(\"MARSH\")\n",
    "    elif \"WOOD\" in x:\n",
    "        return(\"FORESTED SWAMP\")\n",
    "    elif \"SHRUB\" in x:\n",
    "        return(\"SHRUB SWAMP\")\n",
    "    elif len(x) == 0:\n",
    "        return(\"NON WETLAND\")\n",
    "    else:\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Broken Functions\n",
    "\n",
    "place broken functions in this section and set as `Raw NBConvert`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this cell works, but not in the arcpy python environment. \n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf \n",
    "\n",
    "def fn_get_vif(exogs, data):\n",
    "    '''Return VIF (variance inflation factor) DataFrame\n",
    "\n",
    "    Args:\n",
    "    exogs (list): list of exogenous/independent variables\n",
    "    data (DataFrame): the df storing all variables\n",
    "\n",
    "    Returns:\n",
    "    VIF and Tolerance DataFrame for each exogenous variable\n",
    "\n",
    "    Notes:\n",
    "    Assume we have a list of exogenous variable [X1, X2, X3, X4].\n",
    "    To calculate the VIF and Tolerance for each variable, we regress\n",
    "    each of them against other exogenous variables. For instance, the\n",
    "    regression model for X3 is defined as:\n",
    "                        X3 ~ X1 + X2 + X4\n",
    "    And then we extract the R-squared from the model to calculate:\n",
    "                    VIF = 1 / (1 - R-squared)\n",
    "                    Tolerance = 1 - R-squared\n",
    "    The cutoff to detect multicollinearity:\n",
    "                    VIF > 10 or Tolerance < 0.1\n",
    "    '''\n",
    "\n",
    "    # initialize dictionaries\n",
    "    vif_dict, tolerance_dict = {}, {}\n",
    "\n",
    "    # create formula for each exogenous variable\n",
    "    for exog in exogs:\n",
    "        not_exog = [i for i in exogs if i != exog]\n",
    "        formula = f\"{exog} ~ {' + '.join(not_exog)}\"\n",
    "\n",
    "        # extract r-squared from the fit\n",
    "        r_squared = smf.ols(formula, data=data).fit().rsquared\n",
    "\n",
    "        # calculate VIF\n",
    "        vif = 1/(1 - r_squared)\n",
    "        vif_dict[exog] = vif\n",
    "\n",
    "        # calculate tolerance\n",
    "        tolerance = 1 - r_squared\n",
    "        tolerance_dict[exog] = tolerance\n",
    "\n",
    "    # return VIF DataFrame\n",
    "    df_vif = pd.DataFrame({'VIF': vif_dict, 'Tolerance': tolerance_dict})\n",
    "\n",
    "    return df_vif\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def fn_load_TaxParAssess_data():\n",
    "    df = pd.read_pickle(\"outputs/MEP_TaxParAssess.pkl\")\n",
    "    return(df)\n",
    "def fn_join_df_TaxParAssess_on_LOC_ID(df,df_TaxParAssess=None):\n",
    "    if DF_Assess is None:\n",
    "        df = fn_load_TaxParAssess_data()\n",
    "    df.merge(left_df,right_df,on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GENERAL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "In  \u001b[0;34m[11]\u001b[0m:\nLine \u001b[0;34m205\u001b[0m:   BASELINE = GENERAL    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GENERAL' is not defined\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# RESUME HERE 2023-07-05\n",
    "\n",
    "ACTIVE_CRANBERRY_USECODES = ['017','710','270','71','27','17','7100','2700']\n",
    "RETIRED_CRANBERRY_USECODES = ['9','20','20','21','29'] # starts with\n",
    "#df.USECODE == \n",
    "def fn_land_use_conditions_dict_general(df):\n",
    "    '''\n",
    "    '''\n",
    "    active_cranberry = '((df.COVERCODE == 21) & (df.USEGENCODE==7))|(np.isin(df.COVERCODE,[6,7])))'\n",
    "    waterbody = '(np.isin(df.COVERCODE,[22,21]) & np.invert('+active_cranberry+'))'\n",
    "    GENERAL = {\n",
    "\n",
    "        # THE FIRST APPEARING CONDITION TAKES PRIORITY IN NP.SELECT\n",
    "    \n",
    "        # key (LUC): value (condition string)\n",
    "    \n",
    "        # 4: \"Agriculture, Active Cranberry, Flowthrough\"\n",
    "    \n",
    "        4: active_cranberry+' & '+flowthrough,\n",
    "    \n",
    "        # 5: \"Agriculture, Active Cranberry, Non Flowthrough\"\n",
    "    \n",
    "        5: active_cranberry+' & (np.invert('+flowthrough+'))',\n",
    "    \n",
    "        # 11: \"Retired Cranberry, Flowthrough\"\n",
    "    \n",
    "        11: abandoned_cranberry+' & '+flowthrough,\n",
    "    \n",
    "        # 12: \"Retired Cranberry, Non flowthrough\"\n",
    "    \n",
    "        12: abandoned_cranberry+' & np.invert('+flowthrough+')',\n",
    "    \n",
    "        # 1: \"Natural Uplands\"\n",
    "    \n",
    "        1: 'df.COVERCODE.between(8, 12, inclusive=\"both\")',\n",
    "    \n",
    "        # 6: \"Impervious, Roads\"\n",
    "    \n",
    "        6: '(df.COVERCODE == 2) & (df.USEGENCODE == 55)',\n",
    "    \n",
    "        ## 3: \"Agriculture, Non Cranberry\"\n",
    "    \n",
    "        3: 'df.COVERCODE == [False]',\n",
    "    \n",
    "        # 8: \"Recieving Body (Estuary)\"\n",
    "        \n",
    "        8: '(df.COVERCODE == 23)|'+waterbody+')', # note that SUB is a string\n",
    "        \n",
    "        # 9: \"Freshwater Ponds and Lakes\"\n",
    "    \n",
    "        9: '(df.SUB != \"0\") &' + waterbody,\n",
    "    \n",
    "        # 10: \"Wetlands\"\n",
    "    \n",
    "        10: 'df.COVERCODE.between(13, 18, inclusive=\"both\")',\n",
    "    \n",
    "        # 2: \"Mowed Areas (Lawns, Sports Fields, and Golf Courses)\"\n",
    "    \n",
    "        2: 'df.COVERCODE == 5',\n",
    "    \n",
    "        # 7: \"Impervious, Non-Roads\"\n",
    "    \n",
    "        7: '(df.COVERCODE == 2) & (df.USEGENCODE != 55)',\n",
    "    \n",
    "        # 13: \"Other (Bare land or Shoreline)\"\n",
    "    \n",
    "        13: 'np.isin(df.COVERCODE,[19,20])'\n",
    "\n",
    "    }\n",
    "    \n",
    "\n",
    "def fn_land_use_conditions_dict():\n",
    "    '''\n",
    "    GENERATE DICTIONARY OF CONDITIONS FOR RECLASSIFYING LAND USE\n",
    "    '''\n",
    "\n",
    "    # specific active cranberry: where other farming makes up a non zero portion of cultivated and hay/pasture cover types\n",
    "    specific_active_cranberry = '(np.isin(df.CropStatus,\"active\"))'\n",
    "    # general active cranberry: use where active cranberry makes up over 99% of COVERCODE 6 and 7. \n",
    "    general_active_cranberry = '((np.isin(df.CropStatus,\"active\"))|((df.COVERCODE == 21) & (df.USEGENCODE==7))|(np.isin(df.COVERCODE,[6,7])))'\n",
    "    active_cranberry = specific_active_cranberry\n",
    "    abandoned_cranberry = 'np.isin(df[\"FID\"],df[df.CropStatus == \"abandoned\"][\"FID\"])'\n",
    "    flowthrough = 'np.isin(df[\"FID\"],df[df.Bog_type == \"flowthrough\"][\"FID\"])'\n",
    "    terminus = 'np.isin(df[\"FID\"],df[df.ele5pct == \"LE5%\"][\"FID\"])'\n",
    "    flowthrough = terminus\n",
    "    #abandoned_cranberry = '(np.isin(df.CropStatus,\"abandoned\"))'\n",
    "    #flowthrough = '(np.isin(df.Bog_type,\"flowthrough\"))'\n",
    "    waterbody = '(np.isin(df.COVERCODE,[22,21]) & np.invert('+active_cranberry+'))'\n",
    "    \n",
    "    # condition dictionary\n",
    "    SPECIFIC = {\n",
    "        # THE FIRST APPEARING CONDITION TAKES PRIORITY IN NP.SELECT\n",
    "        # key (LUC): value (condition string)\n",
    "        # 4: \"Agriculture, Active Cranberry, Flowthrough\"\n",
    "        4: active_cranberry+' & '+flowthrough,\n",
    "        # 5: \"Agriculture, Active Cranberry, Non Flowthrough\"\n",
    "        5: active_cranberry+' & (np.invert('+flowthrough+'))',\n",
    "    \n",
    "        # 11: \"Retired Cranberry, Flowthrough\"\n",
    "    \n",
    "        11: abandoned_cranberry+' & '+flowthrough,\n",
    "    \n",
    "        # 12: \"Retired Cranberry, Non flowthrough\"\n",
    "    \n",
    "        12: abandoned_cranberry+' & np.invert('+flowthrough+')',\n",
    "    \n",
    "        # 1: \"Natural Uplands\"\n",
    "    \n",
    "        1: '(df.COVERCODE >= 8) & (df.COVERCODE <= 12)',\n",
    "     \n",
    "        # 6: \"Impervious, Roads\"\n",
    "    \n",
    "        6: '(df.COVERCODE == 2)',\n",
    "    \n",
    "        # 3: \"Agriculture, Non Cranberry\"\n",
    "    \n",
    "        3: '(np.isin(df.COVERCODE,[6,7])) & (np.invert('+active_cranberry+'))',\n",
    "    \n",
    "        # 8: \"Recieving Body (Estuary)\"\n",
    "    \n",
    "        8: '(df.SUB == \"0\") & ((df.COVERCODE == 23)|'+waterbody+')', # note that SUB is a string\n",
    "    \n",
    "        # 9: \"Freshwater Ponds and Lakes\"\n",
    "    \n",
    "        9: '(df.SUB != \"0\") &' + waterbody,\n",
    "    \n",
    "        # 10: \"Wetlands\"\n",
    "    \n",
    "        10: '(df.COVERCODE >= 13) & (df.COVERCODE <= 18)',\n",
    "    \n",
    "        # 2: \"Mowed Areas (Lawns, Sports Fields, and Golf Courses)\"\n",
    "    \n",
    "        2: 'df.COVERCODE is [False]', # this will be calculated separately\n",
    "    \n",
    "        # 7: \"Impervious, Non-Roads\"\n",
    "    \n",
    "        7: 'df.COVERCODE is [False]', # this will be calculated separately\n",
    "    \n",
    "        # 13: \"Other (Bare land or Shoreline)\"\n",
    "    \n",
    "        13: 'df.COVERCODE is [False]'}\n",
    "    \n",
    "    GENERAL = {\n",
    "    \n",
    "        # THE FIRST APPEARING CONDITION TAKES PRIORITY IN NP.SELECT\n",
    "    \n",
    "        # key (LUC): value (condition string)\n",
    "    \n",
    "        # 4: \"Agriculture, Active Cranberry, Flowthrough\"\n",
    "    \n",
    "        4: active_cranberry+' & '+flowthrough,\n",
    "    \n",
    "        # 5: \"Agriculture, Active Cranberry, Non Flowthrough\"\n",
    "    \n",
    "        5: active_cranberry+' & (np.invert('+flowthrough+'))',\n",
    "    \n",
    "        # 11: \"Retired Cranberry, Flowthrough\"\n",
    "    \n",
    "        11: abandoned_cranberry+' & '+flowthrough,\n",
    "    \n",
    "        # 12: \"Retired Cranberry, Non flowthrough\"\n",
    "    \n",
    "        12: abandoned_cranberry+' & np.invert('+flowthrough+')',\n",
    "    \n",
    "        # 1: \"Natural Uplands\"\n",
    "    \n",
    "        1: 'df.COVERCODE.between(8, 12, inclusive=\"both\")',\n",
    "    \n",
    "        # 6: \"Impervious, Roads\"\n",
    "    \n",
    "        6: '(df.COVERCODE == 2) & (df.USEGENCODE == 55)',\n",
    "    \n",
    "        ## 3: \"Agriculture, Non Cranberry\"\n",
    "    \n",
    "        3: 'df.COVERCODE == [False]',\n",
    "    \n",
    "        # 8: \"Recieving Body (Estuary)\"\n",
    "        \n",
    "        8: '(df.USEGENCODE == 0) &' +waterbody, \n",
    "        \n",
    "        # 9: \"Freshwater Ponds and Lakes\"\n",
    "    \n",
    "        9: '(df.USEGENCODE == 0 != 0) &' + waterbody,\n",
    "    \n",
    "        # 10: \"Wetlands\"\n",
    "    \n",
    "        10: 'df.COVERCODE.between(13, 18, inclusive=\"both\")',\n",
    "    \n",
    "        # 2: \"Mowed Areas (Lawns, Sports Fields, and Golf Courses)\"\n",
    "    \n",
    "        2: 'df.COVERCODE == 5',\n",
    "    \n",
    "        # 7: \"Impervious, Non-Roads\"\n",
    "    \n",
    "        7: '(df.COVERCODE == 2) & (df.USEGENCODE != 55)',\n",
    "    \n",
    "        # 13: \"Other (Bare land or Shoreline)\"\n",
    "    \n",
    "        13: 'np.isin(df.COVERCODE,[19,20])'\n",
    "\n",
    "    }\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESUME HERE 2023-07-05\n",
    "\n",
    "# specific active cranberry: where other farming makes up a non zero portion of cultivated and hay/pasture cover types\n",
    "specific_active_cranberry = '(np.isin(df.CropStatus,\"active\"))'\n",
    "# general active cranberry: use where active cranberry makes up over 99% of COVERCODE 6 and 7. \n",
    "general_active_cranberry = '((np.isin(df.CropStatus,\"active\"))|((df.COVERCODE == 21) & (df.USEGENCODE==7))|(np.isin(df.COVERCODE,[6,7])))'\n",
    "active_cranberry = specific_active_cranberry\n",
    "abandoned_cranberry = 'np.isin(df[\"FID\"],df[df.CropStatus == \"abandoned\"][\"FID\"])'\n",
    "flowthrough = 'np.isin(df[\"FID\"],df[df.Bog_type == \"flowthrough\"][\"FID\"])'\n",
    "terminus = 'np.isin(df[\"FID\"],df[df.ele5pct == \"LE5%\"][\"FID\"])'\n",
    "flowthrough = terminus\n",
    "#abandoned_cranberry = '(np.isin(df.CropStatus,\"abandoned\"))'\n",
    "#flowthrough = '(np.isin(df.Bog_type,\"flowthrough\"))'\n",
    "waterbody = '(np.isin(df.COVERCODE,[22,21]))'# & np.invert('+active_cranberry+'))'\n",
    "#waterbody = '(np.isin(df.COVERCODE,[22,21]) & np.invert('+active_cranberry+'))'\n",
    "BASELINE = {\n",
    "    \n",
    "        # THE FIRST APPEARING CONDITION TAKES PRIORITY IN NP.SELECT\n",
    "    \n",
    "        # key (LUC): value (condition string)\n",
    "    \n",
    "        # 4: \"Agriculture, Active Cranberry, Flowthrough\"\n",
    "    \n",
    "        4: active_cranberry+' & '+flowthrough,\n",
    "    \n",
    "        # 5: \"Agriculture, Active Cranberry, Non Flowthrough\"\n",
    "    \n",
    "        5: active_cranberry+' & (np.invert('+flowthrough+'))',\n",
    "    \n",
    "        # 11: \"Retired Cranberry, Flowthrough\"\n",
    "    \n",
    "        11: abandoned_cranberry+' & '+flowthrough,\n",
    "    \n",
    "        # 12: \"Retired Cranberry, Non flowthrough\"\n",
    "    \n",
    "        12: abandoned_cranberry+' & np.invert('+flowthrough+')',\n",
    "    \n",
    "        # 1: \"Natural Uplands\"\n",
    "    \n",
    "        1: 'df.COVERCODE.between(8, 12, inclusive=\"both\")',\n",
    "    \n",
    "        # 6: \"Impervious, Roads\"\n",
    "    \n",
    "        6: '(df.COVERCODE == 2) & (df.USEGENCODE == 55)',\n",
    "    \n",
    "        ## 3: \"Agriculture, Non Cranberry\"\n",
    "    \n",
    "        3: 'df.COVERCODE == [False]',\n",
    "    \n",
    "        # 8: \"Recieving Body (Estuary)\"\n",
    "        \n",
    "        8: '(df.USEGENCODE == 0) &' +waterbody, \n",
    "        \n",
    "        # 9: \"Freshwater Ponds and Lakes\"\n",
    "    \n",
    "        9: '(df.USEGENCODE != 0) &' + waterbody,\n",
    "    \n",
    "        # 10: \"Wetlands\"\n",
    "    \n",
    "        10: 'df.COVERCODE.between(13, 18, inclusive=\"both\")',\n",
    "    \n",
    "        # 2: \"Mowed Areas (Lawns, Sports Fields, and Golf Courses)\"\n",
    "    \n",
    "        2: 'df.COVERCODE == 5',\n",
    "    \n",
    "        # 7: \"Impervious, Non-Roads\"\n",
    "    \n",
    "        7: '(df.COVERCODE == 2) & (df.USEGENCODE != 55)',\n",
    "    \n",
    "        # 13: \"Other (Bare land or Shoreline)\"\n",
    "    \n",
    "        13: 'np.isin(df.COVERCODE,[19,20])'\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 (np.isin(df.CropStatus,\"active\")) & np.isin(df[\"FID\"],df[df.ele5pct == \"LE5%\"][\"FID\"]) \n",
      "\n",
      "5 (np.isin(df.CropStatus,\"active\")) & (np.invert(np.isin(df[\"FID\"],df[df.ele5pct == \"LE5%\"][\"FID\"]))) \n",
      "\n",
      "11 np.isin(df[\"FID\"],df[df.CropStatus == \"abandoned\"][\"FID\"]) & np.isin(df[\"FID\"],df[df.ele5pct == \"LE5%\"][\"FID\"]) \n",
      "\n",
      "12 np.isin(df[\"FID\"],df[df.CropStatus == \"abandoned\"][\"FID\"]) & np.invert(np.isin(df[\"FID\"],df[df.ele5pct == \"LE5%\"][\"FID\"])) \n",
      "\n",
      "1 df.COVERCODE.between(8, 12, inclusive=\"both\") \n",
      "\n",
      "6 (df.COVERCODE == 2) & (df.USEGENCODE == 55) \n",
      "\n",
      "3 df.COVERCODE == [False] \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Lengths must match to compare', (4,), (1,))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "In  \u001b[0;34m[13]\u001b[0m:\nLine \u001b[0;34m33\u001b[0m:    df[\u001b[36mstr\u001b[39;49;00m(k)] = \u001b[36meval\u001b[39;49;00m(v)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m, in \u001b[0;32mnew_method\u001b[0m:\nLine \u001b[0;34m81\u001b[0m:    \u001b[34mreturn\u001b[39;49;00m method(\u001b[36mself\u001b[39;49;00m, other)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m, in \u001b[0;32m__eq__\u001b[0m:\nLine \u001b[0;34m40\u001b[0m:    \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._cmp_method(other, operator.eq)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m, in \u001b[0;32m_cmp_method\u001b[0m:\nLine \u001b[0;34m6096\u001b[0m:  res_values = ops.comparison_op(lvalues, rvalues, op)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m, in \u001b[0;32mcomparison_op\u001b[0m:\nLine \u001b[0;34m270\u001b[0m:   \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\u001b[37m\u001b[39;49;00m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Lengths must match to compare', (4,), (1,))\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# checking condtions \n",
    "df = pd.DataFrame({\"FID\":[0,1,2,3],\n",
    "                   \"COVERCODE\":[21,21]*2,\n",
    "                   \"SUB\":[\"0\",\"1\"]*2,\n",
    "                   \"CropStatus\":[\"active\"]*2 + [\"abandoned\"]*2,\n",
    "                   \"Bog_type\":[\"\",\"flowthrough\"]*2,\n",
    "                   'ele5pct':[\"\",\"LE5%\"]*2,\n",
    "                   \"USEGENCODE\":[0,0,0,0],\n",
    "                   \"USE_CODE\":[0,0,0,0]})\n",
    "'''\n",
    "df = pd.DataFrame({\"FID\":[4,5,6,7],\n",
    "                   \"COVERCODE\":[2,5]*2,\n",
    "                   \"SUB\":[\"0\",\"1\"]*2,\n",
    "                   \"CropStatus\":[None]*2 + [None]*2,\n",
    "                   \"Bog_type\":[None,None]*2,\n",
    "                   'ele5pct':[\"\",\"LE5%\"]*2,\n",
    "                   \"USEGENCODE\":[55,55,0,0],\n",
    "                   \"USE_CODE\":[0,0,0,0]})\n",
    "df = pd.DataFrame({\"FID\":[8,9,10,11],\n",
    "                   \"COVERCODE\":[9,15,19,22],\n",
    "                   \"SUB\":[\"0\",\"1\"]*2,\n",
    "                   \"CropStatus\":[None]*2 + [None]*2,\n",
    "                   \"Bog_type\":[None,None]*2,\n",
    "                   'ele5pct':[\"\",\"LE5%\"]*2,\n",
    "                   \"USEGENCODE\":[55,55,0,0],\n",
    "                   \"USE_CODE\":[0,0,0,0]})\n",
    "                   '''\n",
    "for k in BASELINE.keys():\n",
    "    v = BASELINE[k]\n",
    "    print(k,v,\"\\n\")\n",
    "    df[str(k)] = eval(v)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 (np.isin(df.CropStatus,\"active\")) & np.isin(df[\"FID\"],df[df.ele5pct == \"LE5%\"][\"FID\"]) \n",
      "\n",
      "5 (np.isin(df.CropStatus,\"active\")) & (np.invert(np.isin(df[\"FID\"],df[df.ele5pct == \"LE5%\"][\"FID\"]))) \n",
      "\n",
      "11 np.isin(df[\"FID\"],df[df.CropStatus == \"abandoned\"][\"FID\"]) & np.isin(df[\"FID\"],df[df.ele5pct == \"LE5%\"][\"FID\"]) \n",
      "\n",
      "12 np.isin(df[\"FID\"],df[df.CropStatus == \"abandoned\"][\"FID\"]) & np.invert(np.isin(df[\"FID\"],df[df.ele5pct == \"LE5%\"][\"FID\"])) \n",
      "\n",
      "1 df.COVERCODE.between(8, 12, inclusive=\"both\") \n",
      "\n",
      "6 (df.COVERCODE == 2) & (df.USEGENCODE == 55) \n",
      "\n",
      "3 df.COVERCODE == [False] \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Lengths must match to compare', (4,), (1,))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "In  \u001b[0;34m[31]\u001b[0m:\nLine \u001b[0;34m4\u001b[0m:     \u001b[36meval\u001b[39;49;00m(v)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m, in \u001b[0;32mnew_method\u001b[0m:\nLine \u001b[0;34m81\u001b[0m:    \u001b[34mreturn\u001b[39;49;00m method(\u001b[36mself\u001b[39;49;00m, other)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m, in \u001b[0;32m__eq__\u001b[0m:\nLine \u001b[0;34m40\u001b[0m:    \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._cmp_method(other, operator.eq)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\core\\series.py\u001b[0m, in \u001b[0;32m_cmp_method\u001b[0m:\nLine \u001b[0;34m6096\u001b[0m:  res_values = ops.comparison_op(lvalues, rvalues, op)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m, in \u001b[0;32mcomparison_op\u001b[0m:\nLine \u001b[0;34m270\u001b[0m:   \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\u001b[37m\u001b[39;49;00m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Lengths must match to compare', (4,), (1,))\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "for k in BASELINE.keys():\n",
    "    v = BASELINE[k]\n",
    "    print(k,v,\"\\n\")\n",
    "    eval(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 11, 12, 1, 6, 3, 8, 9, 10, 2, 7, 13]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Lengths must match to compare', (4,), (1,))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "In  \u001b[0;34m[27]\u001b[0m:\nLine \u001b[0;34m7\u001b[0m:     df[\u001b[33m\"\u001b[39;49;00m\u001b[33mLUC\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = np.select(\u001b[36meval\u001b[39;49;00m(condlist),choicelist,\u001b[34m13\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m, in \u001b[0;32mnew_method\u001b[0m:\nLine \u001b[0;34m81\u001b[0m:    \u001b[34mreturn\u001b[39;49;00m method(\u001b[36mself\u001b[39;49;00m, other)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m, in \u001b[0;32m__eq__\u001b[0m:\nLine \u001b[0;34m40\u001b[0m:    \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._cmp_method(other, operator.eq)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\core\\series.py\u001b[0m, in \u001b[0;32m_cmp_method\u001b[0m:\nLine \u001b[0;34m6096\u001b[0m:  res_values = ops.comparison_op(lvalues, rvalues, op)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m, in \u001b[0;32mcomparison_op\u001b[0m:\nLine \u001b[0;34m270\u001b[0m:   \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\u001b[37m\u001b[39;49;00m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Lengths must match to compare', (4,), (1,))\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "condlist = \"[\"+\", \".join(list(BASELINE.values()))+\"]\"\n",
    "choicelist = list(BASELINE.keys())\n",
    "print(choicelist)\n",
    "\n",
    "list(BASELINE.values())\n",
    "\n",
    "df[\"LUC\"] = np.select(eval(condlist),choicelist,13)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
