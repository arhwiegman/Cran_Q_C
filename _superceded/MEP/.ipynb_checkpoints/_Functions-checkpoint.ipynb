{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "Adrian Wiegman, adrian.wiegman@usda.gov\n",
    "\n",
    "Created: 10:05 AM Thursday, March 30, 2023\n",
    "\n",
    "Updated: April 18, 2023\n",
    "\n",
    "This script contains helper functions for arcgis workflow to analyze land use and other datasets within watersheds. \n",
    "\n",
    "Notes and Instructions:\n",
    "\n",
    "- prefix all user defined functions with `fn_`\n",
    "- place working functions in the main program\n",
    "- place broken functions in the appendix and comment out or convert cell to Raw NBConvert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program\n",
    "\n",
    "functions in this section have been checked and debugged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type `fn_`+TAB to for autocomplete suggestions\n"
     ]
    }
   ],
   "source": [
    "print('type `fn_`+TAB to for autocomplete suggestions')\n",
    "\n",
    "def fn_get_info(name='fn_get_info'):\n",
    "    '''\n",
    "    returns the source information about a given function name\n",
    "    '''\n",
    "    ??$name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this codeblock appends a path to source codes to the environment variable paths\n",
    "# then runs a script containing other source codes\n",
    "import sys\n",
    "# Insert the path of modules folder \n",
    "sys.path.append(r\"C:\\Users\\Adrian.Wiegman\\Documents\\GitHub\\Wiegman_USDA_ARS\\MEP\\scripts\")\n",
    "# Import the module0 directly since \n",
    "# the current path is of modules.\n",
    "%run -m _FeatureTableToDataFrame \n",
    "# the line above runs the script named _FeaturedTableToDataFrame.py from within the path .../scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_run_script_w_propy_bat(\n",
    "    py_script_path=None, # full path to python script includeing the name e.g. \"C:\\hello.py\"\n",
    "    propy_bat_path=\"C:\\Progra~1\\ArcGIS\\Pro\\\\bin\\Python\\Scripts\"\n",
    "    ):\n",
    "    '''\n",
    "    this function can be used to execute standalone python scripts in the ArcGIS python environment using the command line\n",
    "    the benefit of this is that arcpy can be used without opening arcgis\n",
    "    read more: https://pro.arcgis.com/en/pro-app/latest/arcpy/get-started/using-conda-with-arcgis-pro.htm\n",
    "    '''\n",
    "    import os\n",
    "    # create temporary file for testing the function\n",
    "    if py_script_path is None:\n",
    "        import tempfile\n",
    "        tmpdir = tempfile.TemporaryDirectory()\n",
    "        py_script_path = os.path.join(tmpdir.name,\"hello.py\")\n",
    "            # Open the file for writing.\n",
    "        with open(py_script_path, 'w') as f:\n",
    "            f.write(\"print('Hello World!')\")\n",
    "\n",
    "    # get current working directory\n",
    "    wdr = os.getcwd()\n",
    "    \n",
    "    # change directory to folder containing propy.bat\n",
    "    os.chdir(propy_bat_path) \n",
    "    \n",
    "    # construct cmd\n",
    "    cmd = \"propy.bat {}\".format(py_script_path)\n",
    "    \n",
    "    print(\"running command:\\n\")\n",
    "    print(\"{}\\{}\".format(propy_bat_path,cmd))\n",
    "    # execute cmd\n",
    "    os.system(cmd)\n",
    "    \n",
    "    # change directory back \n",
    "    os.chdir(wdr)\n",
    "#fn_run_script_w_propy_bat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_try_mkdir(dirname):\n",
    "    '''\n",
    "    tries to make a new directory\n",
    "    uses proper error handling \n",
    "    '''\n",
    "    import os, errno\n",
    "    try:\n",
    "        os.mkdir(dirname)\n",
    "    except OSError as exc:\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_hello(x=\"world\"):\n",
    "    '''\n",
    "    prints hello x\n",
    "    '''\n",
    "    print(\"hello %s\" %x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_recursive_glob_search (startDir=None,\n",
    "                             fileExt=\"csv\"):\n",
    "    '''returns:\n",
    "           file paths matching extension \n",
    "           within all subdirectories starting directory\n",
    "       inputs:\n",
    "           startDir = root or parent directory to start search\n",
    "           fileExt = file extension, e.g. \".csv\" \".xlsx\" \".shp\"\n",
    "    '''\n",
    "    import glob, os\n",
    "    if startDir is None:\n",
    "        startDir = os.getcwd\n",
    "    fileList = []\n",
    "    glbsearch = os.path.join(startDir,'**/*'+fileExt)\n",
    "    for f in glob.glob(glbsearch, recursive=True):\n",
    "        #print(f)\n",
    "        fileList.append(f)\n",
    "    return(fileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_regex_search_replace(string,pattern,replacement=None):\n",
    "    '''\n",
    "    returns the a string with a pattern substituted by a replacement\n",
    "    '''\n",
    "    if replacement is None: replacement = \"\"\n",
    "    import re\n",
    "    x = re.sub(pattern,replacement,string)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_regex_search_0 (string,pattern,noneVal=\"NA\"):\n",
    "    '''\n",
    "    returns the first match of a regular expression pattern search on a string\n",
    "    '''\n",
    "    import re\n",
    "    x = re.search(pattern,string)\n",
    "    if x is None: \n",
    "        x= [noneVal]    \n",
    "    return(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_arcpy_table_to_excel(inFeaturePath,outTablePath,outTableName):\n",
    "    import os\n",
    "    arcpy.conversion.TableToExcel(inFeaturePath, os.path.join(outTablePath,outTableName), \"ALIAS\", \"CODE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_agg_sum_df_on_group(group_cols,df,func=sum):\n",
    "    '''\n",
    "    returns data frame aggregated on set of group_cols for given a func\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    return df.groupby(group_cols).aggregate(func).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_add_prefix_suffix_to_selected_cols(df,col_names,prefix=None,suffix=None,sep='_'):\n",
    "    # use list comprehension to add prefix and/or suffix to old names\n",
    "    _ = [i if prefix is None else prefix+sep+i for i in col_names]\n",
    "    new_names = [i if suffix is None else i+sep+suffix for i in _]\n",
    "    df.rename(columns=dict(zip(col_names, new_names)), inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_calc_pct_cover_within_groups(group_cols,x,area_col='Shape_Area'):\n",
    "    '''\n",
    "    calculates percent cover normalize metrics by polygon area\n",
    "    inputs:\n",
    "        x = pandas dataframe containing the following columns\n",
    "        group_cols = a list of strings containing group column names\n",
    "        area_col = string containing the name of the shape area column\n",
    "    all other columns must be numeric columns containing areas of various attribute types \n",
    "    all other columns must have the same units as area_col\n",
    "    '''\n",
    "    x\n",
    "    # copy the numeric columns that are not groups or the selected area column \n",
    "    _ = x.loc[:, ~x.columns.isin(group_cols+[area_col])]._get_numeric_data()\n",
    "    \n",
    "    # divide the \n",
    "    y = _.div(x[area_col],axis=0).mul(100)\n",
    "    if 'Shape_Length' in y.columns:\n",
    "        y.rename(columns={'Shape_Length':'Shape_Perim_to_Area'},inplace=True)\n",
    "    # merge the data back together\n",
    "    z = pd.merge(x[group_cols],x[area_col],left_index=True,right_index=True).merge(y,left_index=True, right_index=True)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Broken Functions\n",
    "\n",
    "place broken functions in this section and set as `Raw NBConvert`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this cell works, but not in the arcpy python environment. \n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf \n",
    "\n",
    "def fn_get_vif(exogs, data):\n",
    "    '''Return VIF (variance inflation factor) DataFrame\n",
    "\n",
    "    Args:\n",
    "    exogs (list): list of exogenous/independent variables\n",
    "    data (DataFrame): the df storing all variables\n",
    "\n",
    "    Returns:\n",
    "    VIF and Tolerance DataFrame for each exogenous variable\n",
    "\n",
    "    Notes:\n",
    "    Assume we have a list of exogenous variable [X1, X2, X3, X4].\n",
    "    To calculate the VIF and Tolerance for each variable, we regress\n",
    "    each of them against other exogenous variables. For instance, the\n",
    "    regression model for X3 is defined as:\n",
    "                        X3 ~ X1 + X2 + X4\n",
    "    And then we extract the R-squared from the model to calculate:\n",
    "                    VIF = 1 / (1 - R-squared)\n",
    "                    Tolerance = 1 - R-squared\n",
    "    The cutoff to detect multicollinearity:\n",
    "                    VIF > 10 or Tolerance < 0.1\n",
    "    '''\n",
    "\n",
    "    # initialize dictionaries\n",
    "    vif_dict, tolerance_dict = {}, {}\n",
    "\n",
    "    # create formula for each exogenous variable\n",
    "    for exog in exogs:\n",
    "        not_exog = [i for i in exogs if i != exog]\n",
    "        formula = f\"{exog} ~ {' + '.join(not_exog)}\"\n",
    "\n",
    "        # extract r-squared from the fit\n",
    "        r_squared = smf.ols(formula, data=data).fit().rsquared\n",
    "\n",
    "        # calculate VIF\n",
    "        vif = 1/(1 - r_squared)\n",
    "        vif_dict[exog] = vif\n",
    "\n",
    "        # calculate tolerance\n",
    "        tolerance = 1 - r_squared\n",
    "        tolerance_dict[exog] = tolerance\n",
    "\n",
    "    # return VIF DataFrame\n",
    "    df_vif = pd.DataFrame({'VIF': vif_dict, 'Tolerance': tolerance_dict})\n",
    "\n",
    "    return df_vif\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def fn_load_TaxParAssess_data():\n",
    "    df = pd.read_pickle(\"outputs/MEP_TaxParAssess.pkl\")\n",
    "    return(df)\n",
    "def fn_join_df_TaxParAssess_on_LOC_ID(df,df_TaxParAssess=None):\n",
    "    if DF_Assess is None:\n",
    "        df = fn_load_TaxParAssess_data()\n",
    "    df.merge(left_df,right_df,on)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# RESUME HERE 2023-07-05\n",
    "\n",
    "ACTIVE_CRANBERRY_USECODES = ['017','710','270','71','27','17','7100','2700']\n",
    "RETIRED_CRANBERRY_USECODES = ['9','20','20','21','29'] # starts with\n",
    "df.USECODE == \n",
    "def fn_land_use_conditions_dict_general(df):\n",
    "    '''\n",
    "    '''\n",
    "    active_cranberry = '((df.COVERCODE == 21) & (df.USEGENCODE==7))|(np.isin(df.COVERCODE,[6,7])))'\n",
    "    waterbody = '(np.isin(df.COVERCODE,[22,21]) & np.invert('+active_cranberry+'))'\n",
    "    GENERAL = {\n",
    "\n",
    "        # THE FIRST APPEARING CONDITION TAKES PRIORITY IN NP.SELECT\n",
    "    \n",
    "        # key (LUC): value (condition string)\n",
    "    \n",
    "        # 4: \"Agriculture, Active Cranberry, Flowthrough\"\n",
    "    \n",
    "        4: active_cranberry+' & '+flowthrough,\n",
    "    \n",
    "        # 5: \"Agriculture, Active Cranberry, Non Flowthrough\"\n",
    "    \n",
    "        5: active_cranberry+' & (np.invert('+flowthrough+'))',\n",
    "    \n",
    "        # 11: \"Retired Cranberry, Flowthrough\"\n",
    "    \n",
    "        11: abandoned_cranberry+' & '+flowthrough,\n",
    "    \n",
    "        # 12: \"Retired Cranberry, Non flowthrough\"\n",
    "    \n",
    "        12: abandoned_cranberry+' & np.invert('+flowthrough+')',\n",
    "    \n",
    "        # 1: \"Natural Uplands\"\n",
    "    \n",
    "        1: 'df.COVERCODE.between(8, 12, inclusive=\"both\")',\n",
    "    \n",
    "        # 6: \"Impervious, Roads\"\n",
    "    \n",
    "        6: '(df.COVERCODE == 2) & (df.USEGENCODE == 55)',\n",
    "    \n",
    "        ## 3: \"Agriculture, Non Cranberry\"\n",
    "    \n",
    "        3: 'df.COVERCODE == [False]',\n",
    "    \n",
    "        # 8: \"Recieving Body (Estuary)\"\n",
    "        \n",
    "        8: '(df.COVERCODE == 23)|'+waterbody+')', # note that SUB is a string\n",
    "        \n",
    "        # 9: \"Freshwater Ponds and Lakes\"\n",
    "    \n",
    "        9: '(df.SUB != \"0\") &' + waterbody,\n",
    "    \n",
    "        # 10: \"Wetlands\"\n",
    "    \n",
    "        10: 'df.COVERCODE.between(13, 18, inclusive=\"both\")',\n",
    "    \n",
    "        # 2: \"Mowed Areas (Lawns, Sports Fields, and Golf Courses)\"\n",
    "    \n",
    "        2: 'df.COVERCODE == 5',\n",
    "    \n",
    "        # 7: \"Impervious, Non-Roads\"\n",
    "    \n",
    "        7: '(df.COVERCODE == 2) & (df.USEGENCODE != 55)',\n",
    "    \n",
    "        # 13: \"Other (Bare land or Shoreline)\"\n",
    "    \n",
    "        13: 'np.isin(df.COVERCODE,[19,20])'\n",
    "\n",
    "    }\n",
    "    \n",
    "\n",
    "def fn_land_use_conditions_dict():\n",
    "    '''\n",
    "    GENERATE DICTIONARY OF CONDITIONS FOR RECLASSIFYING LAND USE\n",
    "    '''\n",
    "\n",
    "    # specific active cranberry: where other farming makes up a non zero portion of cultivated and hay/pasture cover types\n",
    "    specific_active_cranberry = '(np.isin(df.CropStatus,\"active\"))'\n",
    "    # general active cranberry: use where active cranberry makes up over 99% of COVERCODE 6 and 7. \n",
    "    general_active_cranberry = '((np.isin(df.CropStatus,\"active\"))|((df.COVERCODE == 21) & (df.USEGENCODE==7))|(np.isin(df.COVERCODE,[6,7])))'\n",
    "    active_cranberry = specific_active_cranberry\n",
    "    abandoned_cranberry = 'np.isin(df[\"FID\"],df[df.CropStatus == \"abandoned\"][\"FID\"])'\n",
    "    flowthrough = 'np.isin(df[\"FID\"],df[df.Bog_type == \"flowthrough\"][\"FID\"])'\n",
    "    terminus = 'np.isin(df[\"FID\"],df[df.ele5pct == \"LE5%\"][\"FID\"])'\n",
    "    flowthrough = terminus\n",
    "    #abandoned_cranberry = '(np.isin(df.CropStatus,\"abandoned\"))'\n",
    "    #flowthrough = '(np.isin(df.Bog_type,\"flowthrough\"))'\n",
    "    waterbody = '(np.isin(df.COVERCODE,[22,21]) & np.invert('+active_cranberry+'))'\n",
    "    \n",
    "    # condition dictionary\n",
    "    SPECIFIC = {\n",
    "        # THE FIRST APPEARING CONDITION TAKES PRIORITY IN NP.SELECT\n",
    "        # key (LUC): value (condition string)\n",
    "        # 4: \"Agriculture, Active Cranberry, Flowthrough\"\n",
    "        4: active_cranberry+' & '+flowthrough,\n",
    "        # 5: \"Agriculture, Active Cranberry, Non Flowthrough\"\n",
    "        5: active_cranberry+' & (np.invert('+flowthrough+'))',\n",
    "    \n",
    "        # 11: \"Retired Cranberry, Flowthrough\"\n",
    "    \n",
    "        11: abandoned_cranberry+' & '+flowthrough,\n",
    "    \n",
    "        # 12: \"Retired Cranberry, Non flowthrough\"\n",
    "    \n",
    "        12: abandoned_cranberry+' & np.invert('+flowthrough+')',\n",
    "    \n",
    "        # 1: \"Natural Uplands\"\n",
    "    \n",
    "        1: '(df.COVERCODE >= 8) & (df.COVERCODE <= 12)',\n",
    "     \n",
    "        # 6: \"Impervious, Roads\"\n",
    "    \n",
    "        6: '(df.COVERCODE == 2)',\n",
    "    \n",
    "        # 3: \"Agriculture, Non Cranberry\"\n",
    "    \n",
    "        3: '(np.isin(df.COVERCODE,[6,7])) & (np.invert('+active_cranberry+'))',\n",
    "    \n",
    "        # 8: \"Recieving Body (Estuary)\"\n",
    "    \n",
    "        8: '(df.SUB == \"0\") & ((df.COVERCODE == 23)|'+waterbody+')', # note that SUB is a string\n",
    "    \n",
    "        # 9: \"Freshwater Ponds and Lakes\"\n",
    "    \n",
    "        9: '(df.SUB != \"0\") &' + waterbody,\n",
    "    \n",
    "        # 10: \"Wetlands\"\n",
    "    \n",
    "        10: '(df.COVERCODE >= 13) & (df.COVERCODE <= 18)',\n",
    "    \n",
    "        # 2: \"Mowed Areas (Lawns, Sports Fields, and Golf Courses)\"\n",
    "    \n",
    "        2: 'df.COVERCODE is [False]', # this will be calculated separately\n",
    "    \n",
    "        # 7: \"Impervious, Non-Roads\"\n",
    "    \n",
    "        7: 'df.COVERCODE is [False]', # this will be calculated separately\n",
    "    \n",
    "        # 13: \"Other (Bare land or Shoreline)\"\n",
    "    \n",
    "        13: 'df.COVERCODE is [False]'}\n",
    "    \n",
    "    GENERAL = {\n",
    "    \n",
    "        # THE FIRST APPEARING CONDITION TAKES PRIORITY IN NP.SELECT\n",
    "    \n",
    "        # key (LUC): value (condition string)\n",
    "    \n",
    "        # 4: \"Agriculture, Active Cranberry, Flowthrough\"\n",
    "    \n",
    "        4: active_cranberry+' & '+flowthrough,\n",
    "    \n",
    "        # 5: \"Agriculture, Active Cranberry, Non Flowthrough\"\n",
    "    \n",
    "        5: active_cranberry+' & (np.invert('+flowthrough+'))',\n",
    "    \n",
    "        # 11: \"Retired Cranberry, Flowthrough\"\n",
    "    \n",
    "        11: abandoned_cranberry+' & '+flowthrough,\n",
    "    \n",
    "        # 12: \"Retired Cranberry, Non flowthrough\"\n",
    "    \n",
    "        12: abandoned_cranberry+' & np.invert('+flowthrough+')',\n",
    "    \n",
    "        # 1: \"Natural Uplands\"\n",
    "    \n",
    "        1: 'df.COVERCODE.between(8, 12, inclusive=\"both\")',\n",
    "    \n",
    "        # 6: \"Impervious, Roads\"\n",
    "    \n",
    "        6: '(df.COVERCODE == 2) & (df.USEGENCODE == 55)',\n",
    "    \n",
    "        ## 3: \"Agriculture, Non Cranberry\"\n",
    "    \n",
    "        3: 'df.COVERCODE == [False]',\n",
    "    \n",
    "        # 8: \"Recieving Body (Estuary)\"\n",
    "        \n",
    "        8: '(df.SUB == \"0\") & ((df.COVERCODE == 23)|'+waterbody+')', # note that SUB is a string\n",
    "        \n",
    "        # 9: \"Freshwater Ponds and Lakes\"\n",
    "    \n",
    "        9: '(df.SUB != \"0\") &' + waterbody,\n",
    "    \n",
    "        # 10: \"Wetlands\"\n",
    "    \n",
    "        10: 'df.COVERCODE.between(13, 18, inclusive=\"both\")',\n",
    "    \n",
    "        # 2: \"Mowed Areas (Lawns, Sports Fields, and Golf Courses)\"\n",
    "    \n",
    "        2: 'df.COVERCODE == 5',\n",
    "    \n",
    "        # 7: \"Impervious, Non-Roads\"\n",
    "    \n",
    "        7: '(df.COVERCODE == 2) & (df.USEGENCODE != 55)',\n",
    "    \n",
    "        # 13: \"Other (Bare land or Shoreline)\"\n",
    "    \n",
    "        13: 'np.isin(df.COVERCODE,[19,20])'\n",
    "\n",
    "    }\n",
    "    return()\n",
    "\n",
    "\n",
    "BASELINE = GENERAL    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# RESUME HERE 2023-07-05\n",
    "\n",
    "# specific active cranberry: where other farming makes up a non zero portion of cultivated and hay/pasture cover types\n",
    "specific_active_cranberry = '(np.isin(df.CropStatus,\"active\"))'\n",
    "# general active cranberry: use where active cranberry makes up over 99% of COVERCODE 6 and 7. \n",
    "general_active_cranberry = '((np.isin(df.CropStatus,\"active\"))|((df.COVERCODE == 21) & (df.USEGENCODE==7))|(np.isin(df.COVERCODE,[6,7])))'\n",
    "active_cranberry = specific_active_cranberry\n",
    "abandoned_cranberry = 'np.isin(df[\"FID\"],df[df.CropStatus == \"abandoned\"][\"FID\"])'\n",
    "flowthrough = 'np.isin(df[\"FID\"],df[df.Bog_type == \"flowthrough\"][\"FID\"])'\n",
    "terminus = 'np.isin(df[\"FID\"],df[df.ele5pct == \"LE5%\"][\"FID\"])'\n",
    "flowthrough = terminus\n",
    "#abandoned_cranberry = '(np.isin(df.CropStatus,\"abandoned\"))'\n",
    "#flowthrough = '(np.isin(df.Bog_type,\"flowthrough\"))'\n",
    "waterbody = '(np.isin(df.COVERCODE,[22,21]) & np.invert('+active_cranberry+'))'\n",
    "BASELINE = {\n",
    "    \n",
    "        # THE FIRST APPEARING CONDITION TAKES PRIORITY IN NP.SELECT\n",
    "    \n",
    "        # key (LUC): value (condition string)\n",
    "    \n",
    "        # 4: \"Agriculture, Active Cranberry, Flowthrough\"\n",
    "    \n",
    "        4: active_cranberry+' & '+flowthrough,\n",
    "    \n",
    "        # 5: \"Agriculture, Active Cranberry, Non Flowthrough\"\n",
    "    \n",
    "        5: active_cranberry+' & (np.invert('+flowthrough+'))',\n",
    "    \n",
    "        # 11: \"Retired Cranberry, Flowthrough\"\n",
    "    \n",
    "        11: abandoned_cranberry+' & '+flowthrough,\n",
    "    \n",
    "        # 12: \"Retired Cranberry, Non flowthrough\"\n",
    "    \n",
    "        12: abandoned_cranberry+' & np.invert('+flowthrough+')',\n",
    "    \n",
    "        # 1: \"Natural Uplands\"\n",
    "    \n",
    "        1: 'df.COVERCODE.between(8, 12, inclusive=\"both\")',\n",
    "    \n",
    "        # 6: \"Impervious, Roads\"\n",
    "    \n",
    "        6: '(df.COVERCODE == 2) & (df.USEGENCODE == 55)',\n",
    "    \n",
    "        ## 3: \"Agriculture, Non Cranberry\"\n",
    "    \n",
    "        3: 'df.COVERCODE == [False]',\n",
    "    \n",
    "        # 8: \"Recieving Body (Estuary)\"\n",
    "        \n",
    "        8: '(df.SUB == \"0\") & ((df.COVERCODE == 23)|'+waterbody+')', # note that SUB is a string\n",
    "        \n",
    "        # 9: \"Freshwater Ponds and Lakes\"\n",
    "    \n",
    "        9: '(df.SUB != \"0\") &' + waterbody,\n",
    "    \n",
    "        # 10: \"Wetlands\"\n",
    "    \n",
    "        10: 'df.COVERCODE.between(13, 18, inclusive=\"both\")',\n",
    "    \n",
    "        # 2: \"Mowed Areas (Lawns, Sports Fields, and Golf Courses)\"\n",
    "    \n",
    "        2: 'df.COVERCODE == 5',\n",
    "    \n",
    "        # 7: \"Impervious, Non-Roads\"\n",
    "    \n",
    "        7: '(df.COVERCODE == 2) & (df.USEGENCODE != 55)',\n",
    "    \n",
    "        # 13: \"Other (Bare land or Shoreline)\"\n",
    "    \n",
    "        13: 'np.isin(df.COVERCODE,[19,20])'\n",
    "\n",
    "    }\n",
    "\n",
    "# checking condtions \n",
    "df = pd.DataFrame({\"FID\":[0,1,2,3],\n",
    "                   \"COVERCODE\":[21,21]*2,\n",
    "                   \"SUB\":[\"0\",\"1\"]*2,\n",
    "                   \"CropStatus\":[\"active\"]*2 + [\"abandoned\"]*2,\n",
    "                   \"Bog_type\":[\"\",\"flowthrough\"]*2,\n",
    "                   'ele5pct':[\"\",\"LE5%\"]*2,\n",
    "                   \"USEGENCODE\":[0,0,0,0],\n",
    "                   \"USE_CODE\":[0,0,0,0]})\n",
    "'''\n",
    "df = pd.DataFrame({\"FID\":[4,5,6,7],\n",
    "                   \"COVERCODE\":[2,5]*2,\n",
    "                   \"SUB\":[\"0\",\"1\"]*2,\n",
    "                   \"CropStatus\":[None]*2 + [None]*2,\n",
    "                   \"Bog_type\":[None,None]*2,\n",
    "                   'ele5pct':[\"\",\"LE5%\"]*2,\n",
    "                   \"USEGENCODE\":[55,55,0,0],\n",
    "                   \"USE_CODE\":[0,0,0,0]})\n",
    "df = pd.DataFrame({\"FID\":[8,9,10,11],\n",
    "                   \"COVERCODE\":[9,15,19,22],\n",
    "                   \"SUB\":[\"0\",\"1\"]*2,\n",
    "                   \"CropStatus\":[None]*2 + [None]*2,\n",
    "                   \"Bog_type\":[None,None]*2,\n",
    "                   'ele5pct':[\"\",\"LE5%\"]*2,\n",
    "                   \"USEGENCODE\":[55,55,0,0],\n",
    "                   \"USE_CODE\":[0,0,0,0]})\n",
    "                   '''\n",
    "df[\"8\"]= eval(BASELINE[8])\n",
    "df[\"9\"]= eval(BASELINE[9])\n",
    "df[\"11\"]= eval(BASELINE[11])\n",
    "df[\"12\"]= eval(BASELINE[12])\n",
    "df[\"2\"]= eval(BASELINE[2])\n",
    "df[\"6\"]= eval(BASELINE[6])\n",
    "df[\"7\"]= eval(BASELINE[7])\n",
    "df[\"13\"]= eval(BASELINE[13])\n",
    "df[\"10\"]= eval(BASELINE[10])\n",
    "df[\"1\"]= eval(BASELINE[1])\n",
    "\n",
    "condlist = \"[\"+\", \".join(list(BASELINE.values()))+\"]\"\n",
    "print(condlist)\n",
    "choicelist = list(BASELINE.keys())\n",
    "print(choicelist)\n",
    "df[\"LUC\"] = np.select(eval(condlist),choicelist,13)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
