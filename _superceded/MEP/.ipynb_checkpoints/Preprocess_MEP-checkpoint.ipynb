{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEP Preprossessing\n",
    "\n",
    "In this notebook I manipulate watershed boundary layers used for the Massachusetts Estuaries Project, within [MEP study area](https://www.mass.gov/guides/the-massachusetts-estuaries-project-and-reports). \n",
    "\n",
    "1. Regroup subwatershed layers that were split by travel time.\n",
    "2. Calculate the elevation percentile in subs (Lid_Sub_ZS)\n",
    "3. Classify subwatersheds by elevation percentile (ele5pct_poly)\n",
    "4. Intersect elevation classes with subwatersheds (sub_le5pct)\n",
    "5. Intersect elevation classified subwatersheds with tax parcel data (subs_le5_tax)\n",
    "\n",
    "Tax parcel data can then be used to generate land cover classifications within subwatersheds uplands and terminal zones (seepage faces) of subwatersheds.\n",
    "\n",
    "NOTE: whenever you set up a new ArcGIS Pro project with python for batch processing make sure to uncheck `options > geoprocessing > 'add output datasets to open map'` this will save RAM and prevent crashes when you are looping through many files. \n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Consider doing more lidar based metrics such as topographix wetness index or topographic openess index\n",
    "\n",
    "Consider adding slope. \n",
    "\n",
    "Consider summarizing landuse for older years. \n",
    "\n",
    "## Data \n",
    "\n",
    "Publication\n",
    "Carlson, C.S., Masterson, J.P., Walter, D.A., and Barbaro, J.R., 2017, Development of simulated groundwater-contributing areas to selected streams, ponds, coastal water bodies, and production wells in the Plymouth-Carver region and Cape Cod, Massachusetts: U.S. Geological Survey Data Series 1074, 17 p. https://doi.org/10.3133/ds1074\n",
    "\n",
    "Dataset: \n",
    "Carlson, C.S., Masterson, J.P., Walter, D.A., and Barbaro, J.R., 2017, Simulated groundwater-contributing areas to selected streams, ponds, coastal water bodies, and production wells, Plymouth-Carver region and Cape Cod, Massachusetts: U.S. Geological Survey data release, https://doi.org/10.5066/F7V69H2Z.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "loading python modules...\n",
      "\n",
      "  `module_list` contains names of all loaded modules\n",
      "\n",
      "...module loading complete\n",
      "\n",
      "***\n",
      "setting up arcpy environment...\n",
      "\n",
      " input file directory (`idr`): C:\\Workspace\\Geodata\\Massachusetts\\\n",
      " working directory (`wdr`): C:\\Workspace\\Geodata\\MEP\\\n",
      " default geodatabase path: C:\\Workspace\\Geodata\\MEP\\Default.gdb\n",
      " temp dir (`tdr`): C:\\Workspace\\Geodata\\MEP\\temp\n",
      " output dir (`odr`): C:\\Workspace\\Geodata\\MEP\\outputs\n",
      " output coordinate system: NAD_1983_UTM_Zone_19N\n",
      "\n",
      "... env setup complete\n",
      "\n",
      "***\n",
      "loading functions...\n",
      "\n",
      "type `fn_`+TAB to autocomplete\n",
      "\n",
      " the object `def_list` contains user defined function names:\n",
      "   fn_get_info\n",
      "   fn_hello\n",
      "   fn_recursive_glob_search\n",
      "   fn_regex_search_replace\n",
      "   fn_regex_search_0\n",
      "   fn_arcpy_table_to_excel\n",
      "   fn_arcgis_table_to_df\n",
      "   fn_arcgis_table_to_np_to_pd_df\n",
      "\n",
      " use ??{insert fn name} to inspect\n",
      " for example running `??fn_get_info` returns:\n",
      "\u001b[1;31mSignature:\u001b[0m \u001b[0mfn_get_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fn_get_info'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m <no docstring>\n",
      "\u001b[1;31mSource:\u001b[0m   \n",
      "\u001b[1;32mdef\u001b[0m \u001b[0mfn_get_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fn_get_info'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pinfo2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'$name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\workspace\\geodata\\mep\\<ipython-input-1-ba824f911473>\n",
      "\u001b[1;31mType:\u001b[0m      function\n",
      "\n",
      " you can also use `fn_get_info(name={insert fn name})` to do the same thing as `??{insert fn name}`\n",
      "\n",
      "...function loading complete\n",
      "\n",
      "\n",
      "+++SETUP COMPLETE+++\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this codeblock sets up the environment from jupyter notebooks\n",
    "setup_notebook = \"C:/Users/Adrian.Wiegman/Documents/GitHub/Wiegman_USDA_ARS/MEP/_Setup.ipynb\"\n",
    "%run $setup_notebook # magic command to run the notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MysticLakeE'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test function\n",
    "fn_regex_search_0('Mystic Lake GT10 E','\\w+10')\n",
    "fn_regex_search_replace('MysticLakeGT10E','\\wT10','')\n",
    "#fn_regex_search_replace('Mystic Lake  E','  ',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, April 6, 2023 10:45:55 AM\",\"Succeeded at Thursday, April 6, 2023 10:45:55 AM (Elapsed Time: 0.13 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\outputs\\\\MEP_Subwatersheds.shp'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a working copy \n",
    "copyfile = r\"C:\\Workspace\\Geodata\\MEP\\outputs\\MEP_Subwatersheds.shp\"\n",
    "original = r\"C:\\Workspace\\Geodata\\Massachusetts\\MEP\\CC_MV_Subwatersheds\\Subwatersheds.shp\"\n",
    "arcpy.management.Copy(original, copyfile, \"ShapeFile\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 30, 2023 3:54:02 PM\",\"Sorting Attributes...\",\"Dissolving...\",\"Succeeded at Thursday, March 30, 2023 3:54:02 PM (Elapsed Time: 0.39 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\MEP_Subwatersheds_Dissolve'>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dissolve the MEP subwatersheds data\n",
    "outfile = os.path.join(\"MEP_Subwatersheds_Dissolve\")\n",
    "arcpy.management.Dissolve(copyfile, outfile, \"FID\", None, \"MULTI_PART\", \"DISSOLVE_LINES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a new feature class for subwatershed travel time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 30, 2023 3:54:25 PM\",\"Adding Travel_Tim to MEP_Subwatersheds...\",\"Succeeded at Thursday, March 30, 2023 3:54:25 PM (Elapsed Time: 0.05 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\outputs\\\\MEP_Subwatersheds.shp'>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a new feature class for subwatershed travel time. \n",
    "fn_string = \"\"\"def fn_regex_search_0 (string,pattern,noneVal=\"NA\"):\n",
    "    '''\n",
    "    returns the first match of a regular expression pattern search on a string\n",
    "    '''\n",
    "    import re\n",
    "    x = re.search(pattern,string)\n",
    "    if x is None: \n",
    "        x= [noneVal]    \n",
    "    return(x[0])\n",
    "    \"\"\"\n",
    "arcpy.management.CalculateField(copyfile,\n",
    "                                \"Travel_Tim\",\n",
    "                                \"fn_regex_search_0(!SUBWATER_D!,'\\wT10','NA')\",\n",
    "                                \"PYTHON3\",\n",
    "                                fn_string, \"TEXT\", \"NO_ENFORCE_DOMAINS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a new subwatershed name field that excludes travel time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 30, 2023 3:54:32 PM\",\"Adding SUBW_NAME to MEP_Subwatersheds...\",\"Succeeded at Thursday, March 30, 2023 3:54:32 PM (Elapsed Time: 0.05 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\outputs\\\\MEP_Subwatersheds.shp'>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a new subwatershed name field that excludes travel time\n",
    "fn_string = \"\"\"def fn_regex_search_replace(string,pattern,replacement):\n",
    "    '''\n",
    "    returns the a string with a pattern substituted by a replacement\n",
    "    '''\n",
    "    import re\n",
    "    x = re.sub(pattern,replacement,string)\n",
    "    return(x)\"\"\"\n",
    "newField = \"SUBW_NAME\"\n",
    "arcpy.management.CalculateField(copyfile,\n",
    "                                newField,\n",
    "                                \"\"\"fn_regex_search_replace(!SUBWATER_N!,\"\\wT10.*\",\"\")\"\"\", \n",
    "                                \"PYTHON3\",\n",
    "                                fn_string,\n",
    "                                \"TEXT\",\n",
    "                                \"NO_ENFORCE_DOMAINS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 30, 2023 4:35:16 PM\",\"Sorting Attributes...\",\"Dissolving...\",\"Succeeded at Thursday, March 30, 2023 4:35:17 PM (Elapsed Time: 0.56 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\MEP_SUBW_NAME'>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dissolve subwatersheds by subwatershed name.\n",
    "arcpy.management.Dissolve(copyfile,\n",
    "                          \"MEP_SUBW_NAME\", \n",
    "                          \"SUBW_NAME\", None, \"MULTI_PART\", \"DISSOLVE_LINES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the statewide lidar dataset with mask of subwatersheds\n",
    "raster = r\"C:\\Workspace\\Geodata\\Massachusetts\\LiDAR_DEM\\LiDAR_DEM.gdb\\LiDAR_DEM_INT_16bit\"\n",
    "mask = \"MEP_Subwatersheds_Dissolve\"\n",
    "outname = \"lidar_extr\"\n",
    "lidar_extr = arcpy.sa.ExtractByMask(raster,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lidar_extr.save(outname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zonal stats to calc 5th percentile of elevation in each subcatchment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster = \"lidar_extr\"\n",
    "poly = \"outputs/MEP_Subwatersheds\"\n",
    "zonefield = \"SUBW_NAME\"\n",
    "pct = 5  # 5% percentile\n",
    "outname = \"Lid_Sub_ZS\"\n",
    "Lid_Sub_ZS = arcpy.ia.ZonalStatistics(poly, \n",
    "                                      zonefield, \n",
    "                                      raster, \n",
    "                                      \"PERCENTILE\", \n",
    "                                      \"DATA\", \n",
    "                                      \"CURRENT_SLICE\", \n",
    "                                      pct, \n",
    "                                      \"AUTO_DETECT\"); \n",
    "Lid_Sub_ZS.save(os.path.join(outname))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# raster calculator to \n",
    "a = \"lidar_extr\"\n",
    "b = \"Lid_Sub_ZS\"\n",
    "outname = \"lidar_le5pct\"\n",
    "lidar_le5pct = arcpy.ia.RasterCalculator([a,b],\n",
    "                                          [\"a\", \"b\"],\n",
    "                                          \"a<=b\"); \n",
    "lidar_le5pct.save(os.path.join(odr,outname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lidar_extr Lid_Sub_ZS\n"
     ]
    }
   ],
   "source": [
    "a = \"lidar_extr\"\n",
    "b = \"Lid_Sub_ZS\"\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_le5pct = arcpy.ia.LessThanEqual(a,b); \n",
    "lidar_le5pct.save(\"lidar_le5pct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert raster of lidar_le5pct to polygon\n",
    "outfile = \"ele5pct_poly\"\n",
    "poly = arcpy.conversion.RasterToPolygon(\"lidar_le5pct\", outfile, \"SIMPLIFY\", \"VALUE\", \"SINGLE_OUTER_PART\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 30, 2023 4:33:02 PM\",\"Adding ele5pct to ele5pct_poly...\",\"Succeeded at Thursday, March 30, 2023 4:33:11 PM (Elapsed Time: 9.15 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\ele5pct_poly'>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfun = \"\"\"def fn(x):\n",
    "    y = \"GT5%\"\n",
    "    if x == 1: y = \"LE5%\"\n",
    "    return(y)\"\"\"\n",
    "# rename the field gridcode \n",
    "arcpy.management.CalculateField(outfile, \n",
    "                                \"ele5pct\", \n",
    "                                \"fn(!gridcode!)\", \n",
    "                                \"PYTHON3\", \n",
    "                                myfun, \"TEXT\", \"NO_ENFORCE_DOMAINS\")\n",
    "#arcpy.management.AlterField(outfile, 'gridcode', 'ElevLE5pct', 'Elev <= 5% percentile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 30, 2023 4:33:50 PM\",\"Sorting Attributes...\",\"Dissolving...\",\"Succeeded at Thursday, March 30, 2023 4:34:01 PM (Elapsed Time: 11.64 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\ele5pct_poly_diss'>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dissolve new polygon layer by elevation class \n",
    "arcpy.management.Dissolve(\"ele5pct_poly\",\n",
    "                          \"ele5pct_poly_diss\", \n",
    "                          \"ele5pct\", None, \"MULTI_PART\", \"DISSOLVE_LINES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 30, 2023 4:47:24 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Thursday, March 30, 2023 4:47:32 PM (Elapsed Time: 7.83 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\subs_le5pct'>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the identity (intersection) of elevation poly and watershed poly\n",
    "infeat = \"ele5pct_poly_diss\"\n",
    "identfeat = \"outputs/MEP_Subwatersheds\"\n",
    "outname = \"subs_le5pct\"\n",
    "arcpy.analysis.Identity(infeat, identfeat, \n",
    "                        outname, \"ALL\", None, \"NO_RELATIONSHIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 30, 2023 4:47:36 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Thursday, March 30, 2023 4:47:45 PM (Elapsed Time: 8.35 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\subs_travtim_le5pct'>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the identity (intersection) of elevation poly and watershed poly\n",
    "# without travel times\n",
    "infeat = \"ele5pct_poly_diss\"\n",
    "identfeat = \"MEP_SUBW_NAME\"\n",
    "outname = \"subs_travtim_le5pct\"\n",
    "arcpy.analysis.Identity(infeat, identfeat, \n",
    "                        outname, \"ALL\", None, \"NO_RELATIONSHIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 30, 2023 4:49:50 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Thursday, March 30, 2023 4:51:06 PM (Elapsed Time: 1 minutes 16 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Workspace\\\\Geodata\\\\MEP\\\\Default.gdb\\\\subs_le5_tax'>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the identity (intersection) of elevation poly and watershed poly\n",
    "# without travel times\n",
    "infeat = \"subs_le5pct\"\n",
    "identfeat = \"MEP_TaxPar\"\n",
    "outname = \"subs_le5_tax\"\n",
    "arcpy.analysis.Identity(infeat, identfeat, \n",
    "                        outname, \"ALL\", None, \"NO_RELATIONSHIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the identity (intersection) of elevation poly and watershed poly\n",
    "# withtravel times\n",
    "infeat = \"subs_travtim_le5pct\"\n",
    "identfeat = \"MEP_TaxPar\"\n",
    "outname = \"subs_tt_le5_tax\"\n",
    "arcpy.analysis.Identity(infeat, identfeat, \n",
    "                        outname, \"ALL\", None, \"NO_RELATIONSHIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUTION: DO NOT RUN THIS CELL!!!!!!!!!!!!!!\n",
    "# intersect sheds with soil\n",
    "arcpy.analysis.Identity(r\"C:\\Workspace\\Geodata\\MEP\\Default.gdb\\subs_le5pct\", \n",
    "                        r\"C:\\Workspace\\Geodata\\Massachusetts\\Soils_MassGIS.gdb\\SOILS_MUPOLYGON_TOP20\", \n",
    "                        r\"C:\\Workspace\\Geodata\\MEP\\Default.gdb\\subs_le5pct_soil20\", \"ALL\", None, \"NO_RELATIONSHIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "In  \u001b[0;34m[4]\u001b[0m:\nLine \u001b[0;34m4\u001b[0m:     arcpy.analysis.Clip(infeat, clipfeat, \u001b[33m\"\u001b[39;49;00m\u001b[33mlclu16_clip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[34mNone\u001b[39;49;00m)\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\analysis.py\u001b[0m, in \u001b[0;32mClip\u001b[0m:\nLine \u001b[0;34m107\u001b[0m:   retval = convertArcObjectToPythonObject(gp.Clip_analysis(*gp_fixargs((in_features, clip_features, out_feature_class, cluster_tolerance), \u001b[34mTrue\u001b[39;49;00m)))\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001b[0m, in \u001b[0;32m<lambda>\u001b[0m:\nLine \u001b[0;34m512\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m \u001b[34mlambda\u001b[39;49;00m *args: val(*gp_fixargs(args, \u001b[34mTrue\u001b[39;49;00m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: \n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# CAUTION: DO NOT RUN THIS CELL!!!!!!!!!!!!!!\n",
    "# intersect \n",
    "infeat = r\"C:\\Workspace\\Geodata\\Massachusetts\\lclu_gdb\\MA_LCLU2016.gdb\\LANDCOVER_LANDUSE_POLY\"\n",
    "clipfeat = \"MEP_SUBW_NAME\"\n",
    "outname = \"lclu16_clip\"\n",
    "arcpy.analysis.Clip(infeat, clipfeat, \"lclu16_clip\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute the itentity intersection of the output with the LCLU layer.\n",
    "infeat = \"subs_le5pct\"\n",
    "identfeat = \"lclu16_clip\"\n",
    "outname = 'subs_le5_lclu16'\n",
    "arcpy.analysis.Identity(infeat, identfeat, outname, \"ALL\", None, \"NO_RELATIONSHIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-03-30 RESUME HERE! \n",
    "# export feature table data \n",
    "print(def_list)\n",
    "\n",
    "# the functions below provide options to export feature tables \n",
    "??fn_arcpy_table_to_excel\n",
    "#fn_arcpy_table_to_excel(inFeaturePath,outTablePath=odr,outTableName=\"SUBS_TaxParAssess.xlsx\")\n",
    "\n",
    "??fn_arcgis_table_to_df #this one works better\n",
    "\n",
    "??fn_arcgis_table_to_np_to_pd_df # this one doesn't work very well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'Shape', 'FID_subs_le5pct', 'FID_ele5pct_poly_diss', 'ele5pct', 'FID_MEP_Subwatersheds', 'OBJECTID_1', 'OBJECTID_12', 'SUBWATER_I', 'SUBWATER_N', 'SUBWATER_D', 'EMBAY_ID', 'EMBAY_NAME', 'EMBAY_DISP', 'X_Centroid', 'Y_Centroid', 'Acreage', 'GeoString', 'Shape_Leng', 'Travel_Tim', 'SUBW_NAME', 'FID_MEP_TaxPar', 'MAP_PAR_ID', 'LOC_ID', 'POLY_TYPE', 'MAP_NO', 'SOURCE', 'PLAN_ID', 'LAST_EDIT', 'BND_CHK', 'NO_MATCH', 'TOWN_ID', 'MERGE_SRC', 'Shape_Length', 'Shape_Area']\n"
     ]
    }
   ],
   "source": [
    "inFeat = 'subs_le5_tax'\n",
    "field_names = [f.name for f in arcpy.ListFields(inFeat)]\n",
    "print(field_names)\n",
    "\n",
    "# convert feature table to pandas data frame\n",
    "df = fn_arcgis_table_to_df(in_fc='subs_le5_tax')\n",
    "\n",
    "# remove unwanted columns\n",
    "selected_fields = ['OBJECTID','SUBW_NAME','LOC_ID','ele5pct','Travel_Tim',\"EMBAY_NAME\",\"SUBWATER_N\",\"Shape_Length\",\"Shape_Area\"]\n",
    "df_select =df.filter(selected_fields,axis=1) # filter columns on index; use axis = 1 for cols use axis = 0 for rows)\n",
    "\n",
    "# save pickle\n",
    "df.to_pickle(os.path.join(odr,'df_'+infeat+'.pkl'))\n",
    "df_select.to_pickle(os.path.join(odr,'df_'+infeat+'_select.pkl'))\n",
    "\n",
    "# save csv\n",
    "df.to_csv(os.path.join(odr,'df_'+infeat+'.csv'))\n",
    "df_select.to_csv(os.path.join(odr,'df_'+infeat+'_select.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'Shape', 'FID_subs_le5pct', 'FID_ele5pct_poly_diss', 'ele5pct', 'FID_MEP_Subwatersheds', 'OBJECTID_1', 'OBJECTID_12', 'SUBWATER_I', 'SUBWATER_N', 'SUBWATER_D', 'EMBAY_ID', 'EMBAY_NAME', 'EMBAY_DISP', 'X_Centroid', 'Y_Centroid', 'Acreage', 'GeoString', 'Shape_Leng', 'Travel_Tim', 'SUBW_NAME', 'FID_SOILS_MUPOLYGON_TOP20', 'AREASYMBOL', 'SPATIALVER', 'MUSYM', 'MUKEY', 'SS_AREA', 'MUSYM_AREA', 'SLOPE', 'AREANAME', 'MUNAME', 'COMPNAME', 'MUKIND', 'FRMLNDCLS', 'HYDRCRATNG', 'DRAINCLASS', 'MINSURFTEXT', 'TFACTOR', 'AWS100', 'AWS25', 'DEP2WATTBL', 'DWELLWB', 'HYDROLGRP', 'NIRRLCC', 'ROADS', 'SEPTANKAF', 'SLOPE_1', 'FLOODING', 'PONDING', 'CORCONCRET', 'TAXCLNAME', 'CM2RESLYR', 'RESKIND', 'PARMATNM', 'UNIFSOILCL', 'AASHTO', 'KFACTRF', 'KFACTWS', 'PHWATER', 'CLAY', 'KSAT', 'OM', 'SAND', 'NLEACHING', 'Shape_Length', 'Shape_Area']\n"
     ]
    }
   ],
   "source": [
    "infeat = 'subs_le5pct_soil20'\n",
    "field_names = [f.name for f in arcpy.ListFields(infeat)]\n",
    "print(field_names)\n",
    "\n",
    "# convert feature table to pandas data frame\n",
    "df = fn_arcgis_table_to_df(in_fc=infeat)\n",
    "\n",
    "# remove unwanted columns\n",
    "selected_fields = ['OBJECTID','SUBW_NAME','LOC_ID','ele5pct','Travel_Tim',\"EMBAY_NAME\",\"SUBWATER_N\",\"Shape_Length\",\"Shape_Area\", # watershed attributes\n",
    "                  \"COMPNAME\",\"SLOPE\",\"SLOPE_1\",\"FRMLNDCLS\",'HYDROLGRP','HYDRCRATNG','DRAINCLASS','DEP2WATTBL'] #soil attributes\n",
    "df_select =df.filter(selected_fields,axis=1) # filter columns on index; use axis = 1 for cols use axis = 0 for rows)\n",
    "\n",
    "# save pickle\n",
    "df.to_pickle(os.path.join(odr,'df_'+infeat+'.pkl'))\n",
    "df_select.to_pickle(os.path.join(odr,'df_'+infeat+'_select.pkl'))\n",
    "\n",
    "# save csv\n",
    "df.to_csv(os.path.join(odr,'df_'+infeat+'.csv'))\n",
    "df_select.to_csv(os.path.join(odr,'df_'+infeat+'_select.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'Shape', 'FID_subs_le5pct', 'FID_ele5pct_poly_diss', 'ele5pct', 'FID_MEP_Subwatersheds', 'OBJECTID_1', 'OBJECTID_12', 'SUBWATER_I', 'SUBWATER_N', 'SUBWATER_D', 'EMBAY_ID', 'EMBAY_NAME', 'EMBAY_DISP', 'X_Centroid', 'Y_Centroid', 'Acreage', 'GeoString', 'Shape_Leng', 'Travel_Tim', 'SUBW_NAME', 'FID_LANDCOVER_LANDUSE_POLY', 'COVERNAME', 'COVERCODE', 'USEGENNAME', 'USEGENCODE', 'USE_CODE', 'POLY_TYPE', 'FY', 'TOWN_ID', 'TILENAME', 'Shape_Length', 'Shape_Area']\n"
     ]
    }
   ],
   "source": [
    "infeat = 'subs_ele5_lclu16'\n",
    "field_names = [f.name for f in arcpy.ListFields(infeat)]\n",
    "print(field_names)\n",
    "\n",
    "# convert feature table to pandas data frame\n",
    "df = fn_arcgis_table_to_df(in_fc=infeat)\n",
    "\n",
    "# remove unwanted columns\n",
    "selected_fields = ['OBJECTID','SUBW_NAME','LOC_ID','ele5pct','Travel_Tim',\"EMBAY_NAME\",\"SUBWATER_N\",\"Shape_Length\",\"Shape_Area\", # watershed attributes\n",
    "                  \"USE_CODE\",\"USEGENCODE\",\"COVERCODE\",\"COVERNAME\",'USEGENNAME'] #land use attributes\n",
    "df_select =df.filter(selected_fields,axis=1) # filter columns on index; use axis = 1 for cols use axis = 0 for rows)\n",
    "\n",
    "# save pickle\n",
    "df.to_pickle(os.path.join(odr,'df_'+infeat+'.pkl'))\n",
    "df_select.to_pickle(os.path.join(odr,'df_'+infeat+'_select.pkl'))\n",
    "\n",
    "# save csv\n",
    "df.to_csv(os.path.join(odr,'df_'+infeat+'.csv'))\n",
    "df_select.to_csv(os.path.join(odr,'df_'+infeat+'_select.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'Shape', 'FID_ele5pct_poly_diss', 'ele5pct', 'FID_MEP_Subwatersheds', 'OBJECTID_1', 'OBJECTID_12', 'SUBWATER_I', 'SUBWATER_N', 'SUBWATER_D', 'EMBAY_ID', 'EMBAY_NAME', 'EMBAY_DISP', 'X_Centroid', 'Y_Centroid', 'Acreage', 'GeoString', 'Shape_Leng', 'Travel_Tim', 'SUBW_NAME', 'Shape_Length', 'Shape_Area']\n"
     ]
    }
   ],
   "source": [
    "infeat = 'subs_le5pct'\n",
    "field_names = [f.name for f in arcpy.ListFields(infeat)]\n",
    "print(field_names)\n",
    "\n",
    "# convert feature table to pandas data frame\n",
    "df = fn_arcgis_table_to_df(in_fc=infeat)\n",
    "\n",
    "# remove unwanted columns\n",
    "selected_fields = ['OBJECTID','SUBW_NAME','ele5pct','Travel_Tim',\"EMBAY_NAME\",\"SUBWATER_N\",\"Shape_Length\",\"Shape_Area\"]\n",
    "df_select =df.filter(selected_fields,axis=1) # filter columns on index; use axis = 1 for cols use axis = 0 for rows)\n",
    "\n",
    "# save pickle\n",
    "df.to_pickle(os.path.join(odr,'df_'+infeat+'.pkl'))\n",
    "df_select.to_pickle(os.path.join(odr,'df_'+infeat+'_select.pkl'))\n",
    "\n",
    "# save csv\n",
    "df.to_csv(os.path.join(odr,'df_'+infeat+'.csv'))\n",
    "df_select.to_csv(os.path.join(odr,'df_'+infeat+'_select.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBW_NAME</th>\n",
       "      <th>ele5pct</th>\n",
       "      <th>Travel_Tim</th>\n",
       "      <th>EMBAY_NAME</th>\n",
       "      <th>SUBWATER_N</th>\n",
       "      <th>Shape_Length</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>USE_CODE</th>\n",
       "      <th>USEGENCODE</th>\n",
       "      <th>COVERCODE</th>\n",
       "      <th>COVERNAME</th>\n",
       "      <th>USEGENNAME</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBJECTID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NashaquitsaPond</td>\n",
       "      <td>GT5%</td>\n",
       "      <td>NA</td>\n",
       "      <td>MenemshaSquibnocketPond</td>\n",
       "      <td>NashaquitsaPond</td>\n",
       "      <td>4.705809</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TashmooPondMain</td>\n",
       "      <td>GT5%</td>\n",
       "      <td>NA</td>\n",
       "      <td>LakeTashmoo</td>\n",
       "      <td>TashmooPondMain</td>\n",
       "      <td>4.579976</td>\n",
       "      <td>0.438198</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>Bare Land</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TashmooPondMain</td>\n",
       "      <td>GT5%</td>\n",
       "      <td>NA</td>\n",
       "      <td>LakeTashmoo</td>\n",
       "      <td>TashmooPondMain</td>\n",
       "      <td>22.081875</td>\n",
       "      <td>11.682190</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>Bare Land</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TashmooPondMain</td>\n",
       "      <td>GT5%</td>\n",
       "      <td>NA</td>\n",
       "      <td>LakeTashmoo</td>\n",
       "      <td>TashmooPondMain</td>\n",
       "      <td>38.322392</td>\n",
       "      <td>13.874547</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>Bare Land</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TashmooPondMain</td>\n",
       "      <td>GT5%</td>\n",
       "      <td>NA</td>\n",
       "      <td>LakeTashmoo</td>\n",
       "      <td>TashmooPondMain</td>\n",
       "      <td>2.206339</td>\n",
       "      <td>0.198506</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Impervious</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SUBW_NAME ele5pct Travel_Tim               EMBAY_NAME  \\\n",
       "OBJECTID                                                                \n",
       "1         NashaquitsaPond    GT5%         NA  MenemshaSquibnocketPond   \n",
       "2         TashmooPondMain    GT5%         NA              LakeTashmoo   \n",
       "3         TashmooPondMain    GT5%         NA              LakeTashmoo   \n",
       "4         TashmooPondMain    GT5%         NA              LakeTashmoo   \n",
       "5         TashmooPondMain    GT5%         NA              LakeTashmoo   \n",
       "\n",
       "               SUBWATER_N  Shape_Length  Shape_Area USE_CODE  USEGENCODE  \\\n",
       "OBJECTID                                                                   \n",
       "1         NashaquitsaPond      4.705809   -0.001061                    0   \n",
       "2         TashmooPondMain      4.579976    0.438198     None           0   \n",
       "3         TashmooPondMain     22.081875   11.682190     None           0   \n",
       "4         TashmooPondMain     38.322392   13.874547     None           0   \n",
       "5         TashmooPondMain      2.206339    0.198506     None           0   \n",
       "\n",
       "          COVERCODE   COVERNAME USEGENNAME  \n",
       "OBJECTID                                    \n",
       "1                 0                         \n",
       "2                20   Bare Land    Unknown  \n",
       "3                20   Bare Land    Unknown  \n",
       "4                20   Bare Land    Unknown  \n",
       "5                 2  Impervious    Unknown  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join table with tax parcel assessor data\n",
    "df_select.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a new feature class subwatershed ids exluding travel time\n",
    "\n",
    "make new sub watershed layer that combines subwatersheds that were split by travel time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a point feature layer from monitoring coordinates\n",
    "# Set the local variables\n",
    "in_table = r\"C:\\Users\\Adrian.Wiegman\\OneDrive - USDA\\Research\\Nload\\MEP\\MEP_Summary4_AW.xlsx\\Coords$\"\n",
    "#in_table = r\"C:\\Users\\Adrian.Wiegman\\OneDrive - USDA\\Research\\Nload\\MEP\\MEP_Monitoring_Site_Coords.csv\"\n",
    "out_feature_class = \"MEP_Monitoring_Site_Coords\"\n",
    "x_coords = \"Lon\"\n",
    "y_coords = \"Lat\"\n",
    "\n",
    "# Make the XY event layer...\n",
    "arcpy.management.XYTableToPoint(in_table=in_table, \n",
    "                                out_feature_class=out_feature_class,\n",
    "                                x_field=x_coords, \n",
    "                                y_field=y_coords)\n",
    "\n",
    "# Print the total rows\n",
    "print(arcpy.management.GetCount(out_feature_class))\n",
    "#arcpy.management.AddJoin(out_feature_class, \"OBJECTID\", r\"C:\\Users\\Adrian.Wiegman\\OneDrive - USDA\\Research\\Nload\\MEP\\MEP_Monitoring_Site_Coords.csv\", \"OID\", \"KEEP_ALL\", \"NO_INDEX_JOIN_FIELDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unused code snippets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# clip the MassGIS 2016 landcover 0.5m layer with the mep watershed layer. \n",
    "# arcgis does not like this for whatever reason. \n",
    "cliplayer = os.path.join(odr,\"MEP_Subwatersheds_Dissolve\")\n",
    "outfile='lclu16_mep_clip'\n",
    "inlayer= 'Land Cover Land Use (2016)'\n",
    "lclu16_clip = arcpy.analysis.Clip(inlayer,cliplayer,outfile, None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "USGS_startDir = r'C:\\Workspace\\Geodata\\Massachusetts\\USGS_\\SimulatedGround\\original_USGS_areas\\original_USGS_areas'\n",
    "All_USGS_paths = fn_recursive_glob_search(USGS_startDir,'.shp')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# clip land use for aquifer extent\n",
    "arcpy.analysis.Clip(r\"C:\\Workspace\\Geodata\\Massachusetts\\lclu_gdb\\MA_LCLU2016.gdb\\LANDCOVER_LANDUSE_POLY\", \"MEP_Subwatersheds\", r\"C:\\Workspace\\Geodata\\Nload\\outputs\\MEP\\LCLU2016_MEP_Clip\", None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
